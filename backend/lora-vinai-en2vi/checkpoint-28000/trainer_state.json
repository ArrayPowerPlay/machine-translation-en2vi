{
  "best_global_step": 28000,
  "best_metric": 1.3149025440216064,
  "best_model_checkpoint": "/kaggle/working/lora-vinai-en2vi/checkpoint-28000",
  "epoch": 1.9910755555555557,
  "eval_steps": 500,
  "global_step": 28000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0071111111111111115,
      "grad_norm": 0.41002926230430603,
      "learning_rate": 0.00019953068335348077,
      "loss": 1.4248,
      "step": 100
    },
    {
      "epoch": 0.014222222222222223,
      "grad_norm": 0.3857014775276184,
      "learning_rate": 0.00019905662613477448,
      "loss": 1.427,
      "step": 200
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 0.35468047857284546,
      "learning_rate": 0.00019858256891606816,
      "loss": 1.3545,
      "step": 300
    },
    {
      "epoch": 0.028444444444444446,
      "grad_norm": 0.40417608618736267,
      "learning_rate": 0.0001981085116973619,
      "loss": 1.377,
      "step": 400
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.3654148280620575,
      "learning_rate": 0.00019763445447865558,
      "loss": 1.4217,
      "step": 500
    },
    {
      "epoch": 0.035555555555555556,
      "eval_loss": 1.3731459379196167,
      "eval_runtime": 260.7863,
      "eval_samples_per_second": 191.728,
      "eval_steps_per_second": 11.983,
      "step": 500
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.26891300082206726,
      "learning_rate": 0.0001971603972599493,
      "loss": 1.3765,
      "step": 600
    },
    {
      "epoch": 0.049777777777777775,
      "grad_norm": 0.47253838181495667,
      "learning_rate": 0.00019668634004124297,
      "loss": 1.3838,
      "step": 700
    },
    {
      "epoch": 0.05688888888888889,
      "grad_norm": 0.36766761541366577,
      "learning_rate": 0.0001962122828225367,
      "loss": 1.392,
      "step": 800
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.3432129919528961,
      "learning_rate": 0.0001957382256038304,
      "loss": 1.3766,
      "step": 900
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.3039953112602234,
      "learning_rate": 0.0001952641683851241,
      "loss": 1.3584,
      "step": 1000
    },
    {
      "epoch": 0.07111111111111111,
      "eval_loss": 1.3639856576919556,
      "eval_runtime": 261.9813,
      "eval_samples_per_second": 190.853,
      "eval_steps_per_second": 11.928,
      "step": 1000
    },
    {
      "epoch": 0.07822222222222222,
      "grad_norm": 0.4184260070323944,
      "learning_rate": 0.00019479011116641778,
      "loss": 1.375,
      "step": 1100
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.39511996507644653,
      "learning_rate": 0.00019431605394771152,
      "loss": 1.3641,
      "step": 1200
    },
    {
      "epoch": 0.09244444444444444,
      "grad_norm": 0.4812295734882355,
      "learning_rate": 0.0001938419967290052,
      "loss": 1.3784,
      "step": 1300
    },
    {
      "epoch": 0.09955555555555555,
      "grad_norm": 0.3704856038093567,
      "learning_rate": 0.0001933679395102989,
      "loss": 1.3604,
      "step": 1400
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.2996755540370941,
      "learning_rate": 0.0001928938822915926,
      "loss": 1.3956,
      "step": 1500
    },
    {
      "epoch": 0.10666666666666667,
      "eval_loss": 1.35720956325531,
      "eval_runtime": 261.1824,
      "eval_samples_per_second": 191.437,
      "eval_steps_per_second": 11.965,
      "step": 1500
    },
    {
      "epoch": 0.11377777777777778,
      "grad_norm": 0.2776728868484497,
      "learning_rate": 0.00019241982507288633,
      "loss": 1.3841,
      "step": 1600
    },
    {
      "epoch": 0.12088888888888889,
      "grad_norm": 0.402092307806015,
      "learning_rate": 0.00019194576785418,
      "loss": 1.3743,
      "step": 1700
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.40460678935050964,
      "learning_rate": 0.00019147171063547372,
      "loss": 1.3883,
      "step": 1800
    },
    {
      "epoch": 0.1351111111111111,
      "grad_norm": 0.35121801495552063,
      "learning_rate": 0.0001909976534167674,
      "loss": 1.3686,
      "step": 1900
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.39081764221191406,
      "learning_rate": 0.0001905235961980611,
      "loss": 1.3991,
      "step": 2000
    },
    {
      "epoch": 0.14222222222222222,
      "eval_loss": 1.3544038534164429,
      "eval_runtime": 261.2838,
      "eval_samples_per_second": 191.363,
      "eval_steps_per_second": 11.96,
      "step": 2000
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.3532598912715912,
      "learning_rate": 0.00019004953897935482,
      "loss": 1.4104,
      "step": 2100
    },
    {
      "epoch": 0.15644444444444444,
      "grad_norm": 0.3594302237033844,
      "learning_rate": 0.00018957548176064853,
      "loss": 1.389,
      "step": 2200
    },
    {
      "epoch": 0.16355555555555557,
      "grad_norm": 0.38840314745903015,
      "learning_rate": 0.00018910142454194221,
      "loss": 1.4019,
      "step": 2300
    },
    {
      "epoch": 0.17066666666666666,
      "grad_norm": 0.49881207942962646,
      "learning_rate": 0.00018862736732323592,
      "loss": 1.3623,
      "step": 2400
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.3681194484233856,
      "learning_rate": 0.00018815331010452963,
      "loss": 1.4039,
      "step": 2500
    },
    {
      "epoch": 0.17777777777777778,
      "eval_loss": 1.3520687818527222,
      "eval_runtime": 261.1558,
      "eval_samples_per_second": 191.457,
      "eval_steps_per_second": 11.966,
      "step": 2500
    },
    {
      "epoch": 0.18488888888888888,
      "grad_norm": 0.35260578989982605,
      "learning_rate": 0.00018767925288582334,
      "loss": 1.3366,
      "step": 2600
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.33728834986686707,
      "learning_rate": 0.00018720519566711702,
      "loss": 1.3593,
      "step": 2700
    },
    {
      "epoch": 0.1991111111111111,
      "grad_norm": 0.35410642623901367,
      "learning_rate": 0.00018673113844841073,
      "loss": 1.3727,
      "step": 2800
    },
    {
      "epoch": 0.20622222222222222,
      "grad_norm": 0.4237496852874756,
      "learning_rate": 0.00018625708122970444,
      "loss": 1.3728,
      "step": 2900
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.33475643396377563,
      "learning_rate": 0.00018578302401099815,
      "loss": 1.3801,
      "step": 3000
    },
    {
      "epoch": 0.21333333333333335,
      "eval_loss": 1.3477579355239868,
      "eval_runtime": 261.3204,
      "eval_samples_per_second": 191.336,
      "eval_steps_per_second": 11.958,
      "step": 3000
    },
    {
      "epoch": 0.22044444444444444,
      "grad_norm": 0.40478625893592834,
      "learning_rate": 0.00018530896679229183,
      "loss": 1.4068,
      "step": 3100
    },
    {
      "epoch": 0.22755555555555557,
      "grad_norm": 0.4083336591720581,
      "learning_rate": 0.00018483490957358554,
      "loss": 1.3784,
      "step": 3200
    },
    {
      "epoch": 0.23466666666666666,
      "grad_norm": 0.4233112931251526,
      "learning_rate": 0.00018436085235487923,
      "loss": 1.3287,
      "step": 3300
    },
    {
      "epoch": 0.24177777777777779,
      "grad_norm": 0.38976696133613586,
      "learning_rate": 0.00018388679513617296,
      "loss": 1.3753,
      "step": 3400
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.43358346819877625,
      "learning_rate": 0.00018341273791746664,
      "loss": 1.3627,
      "step": 3500
    },
    {
      "epoch": 0.24888888888888888,
      "eval_loss": 1.3463484048843384,
      "eval_runtime": 260.8309,
      "eval_samples_per_second": 191.695,
      "eval_steps_per_second": 11.981,
      "step": 3500
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.3764401972293854,
      "learning_rate": 0.00018293868069876035,
      "loss": 1.3438,
      "step": 3600
    },
    {
      "epoch": 0.26311111111111113,
      "grad_norm": 0.37402021884918213,
      "learning_rate": 0.00018246462348005404,
      "loss": 1.3767,
      "step": 3700
    },
    {
      "epoch": 0.2702222222222222,
      "grad_norm": 0.3553975522518158,
      "learning_rate": 0.00018199056626134777,
      "loss": 1.3454,
      "step": 3800
    },
    {
      "epoch": 0.2773333333333333,
      "grad_norm": 0.35114771127700806,
      "learning_rate": 0.00018151650904264146,
      "loss": 1.3931,
      "step": 3900
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.34072473645210266,
      "learning_rate": 0.00018104245182393516,
      "loss": 1.3731,
      "step": 4000
    },
    {
      "epoch": 0.28444444444444444,
      "eval_loss": 1.3434323072433472,
      "eval_runtime": 260.8193,
      "eval_samples_per_second": 191.704,
      "eval_steps_per_second": 11.981,
      "step": 4000
    },
    {
      "epoch": 0.29155555555555557,
      "grad_norm": 0.36683714389801025,
      "learning_rate": 0.00018056839460522885,
      "loss": 1.3658,
      "step": 4100
    },
    {
      "epoch": 0.2986666666666667,
      "grad_norm": 0.3781152367591858,
      "learning_rate": 0.00018009433738652258,
      "loss": 1.3511,
      "step": 4200
    },
    {
      "epoch": 0.30577777777777776,
      "grad_norm": 0.3405027985572815,
      "learning_rate": 0.00017962028016781627,
      "loss": 1.4013,
      "step": 4300
    },
    {
      "epoch": 0.3128888888888889,
      "grad_norm": 0.34913018345832825,
      "learning_rate": 0.00017914622294910997,
      "loss": 1.3761,
      "step": 4400
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.3393286466598511,
      "learning_rate": 0.00017867216573040366,
      "loss": 1.3387,
      "step": 4500
    },
    {
      "epoch": 0.32,
      "eval_loss": 1.342308759689331,
      "eval_runtime": 260.8566,
      "eval_samples_per_second": 191.676,
      "eval_steps_per_second": 11.98,
      "step": 4500
    },
    {
      "epoch": 0.32711111111111113,
      "grad_norm": 0.4038551151752472,
      "learning_rate": 0.0001781981085116974,
      "loss": 1.3699,
      "step": 4600
    },
    {
      "epoch": 0.3342222222222222,
      "grad_norm": 0.31652170419692993,
      "learning_rate": 0.00017772405129299108,
      "loss": 1.3639,
      "step": 4700
    },
    {
      "epoch": 0.3413333333333333,
      "grad_norm": 0.3494918942451477,
      "learning_rate": 0.00017724999407428479,
      "loss": 1.3607,
      "step": 4800
    },
    {
      "epoch": 0.34844444444444445,
      "grad_norm": 0.34721168875694275,
      "learning_rate": 0.00017677593685557847,
      "loss": 1.4063,
      "step": 4900
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.3600306212902069,
      "learning_rate": 0.00017630187963687218,
      "loss": 1.354,
      "step": 5000
    },
    {
      "epoch": 0.35555555555555557,
      "eval_loss": 1.341162085533142,
      "eval_runtime": 260.945,
      "eval_samples_per_second": 191.611,
      "eval_steps_per_second": 11.976,
      "step": 5000
    },
    {
      "epoch": 0.3626666666666667,
      "grad_norm": 0.39623841643333435,
      "learning_rate": 0.00017582782241816589,
      "loss": 1.387,
      "step": 5100
    },
    {
      "epoch": 0.36977777777777776,
      "grad_norm": 0.3546731770038605,
      "learning_rate": 0.0001753537651994596,
      "loss": 1.3705,
      "step": 5200
    },
    {
      "epoch": 0.3768888888888889,
      "grad_norm": 0.39193668961524963,
      "learning_rate": 0.00017487970798075328,
      "loss": 1.3601,
      "step": 5300
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.33968889713287354,
      "learning_rate": 0.000174405650762047,
      "loss": 1.3871,
      "step": 5400
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.4002060890197754,
      "learning_rate": 0.0001739315935433407,
      "loss": 1.3667,
      "step": 5500
    },
    {
      "epoch": 0.39111111111111113,
      "eval_loss": 1.3385941982269287,
      "eval_runtime": 261.5353,
      "eval_samples_per_second": 191.179,
      "eval_steps_per_second": 11.949,
      "step": 5500
    },
    {
      "epoch": 0.3982222222222222,
      "grad_norm": 0.4598955512046814,
      "learning_rate": 0.0001734575363246344,
      "loss": 1.355,
      "step": 5600
    },
    {
      "epoch": 0.4053333333333333,
      "grad_norm": 0.43408113718032837,
      "learning_rate": 0.0001729834791059281,
      "loss": 1.3353,
      "step": 5700
    },
    {
      "epoch": 0.41244444444444445,
      "grad_norm": 0.4244018793106079,
      "learning_rate": 0.0001725094218872218,
      "loss": 1.3453,
      "step": 5800
    },
    {
      "epoch": 0.41955555555555557,
      "grad_norm": 0.40868568420410156,
      "learning_rate": 0.0001720353646685155,
      "loss": 1.3841,
      "step": 5900
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.391977459192276,
      "learning_rate": 0.00017156130744980922,
      "loss": 1.3702,
      "step": 6000
    },
    {
      "epoch": 0.4266666666666667,
      "eval_loss": 1.3382278680801392,
      "eval_runtime": 260.683,
      "eval_samples_per_second": 191.804,
      "eval_steps_per_second": 11.988,
      "step": 6000
    },
    {
      "epoch": 0.43377777777777776,
      "grad_norm": 0.41298016905784607,
      "learning_rate": 0.0001710872502311029,
      "loss": 1.3376,
      "step": 6100
    },
    {
      "epoch": 0.4408888888888889,
      "grad_norm": 0.35812047123908997,
      "learning_rate": 0.0001706131930123966,
      "loss": 1.3792,
      "step": 6200
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.34981462359428406,
      "learning_rate": 0.0001701391357936903,
      "loss": 1.3555,
      "step": 6300
    },
    {
      "epoch": 0.45511111111111113,
      "grad_norm": 0.3893825113773346,
      "learning_rate": 0.00016966507857498403,
      "loss": 1.3466,
      "step": 6400
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.3894365429878235,
      "learning_rate": 0.0001691910213562777,
      "loss": 1.368,
      "step": 6500
    },
    {
      "epoch": 0.4622222222222222,
      "eval_loss": 1.3378515243530273,
      "eval_runtime": 258.3995,
      "eval_samples_per_second": 193.499,
      "eval_steps_per_second": 12.094,
      "step": 6500
    },
    {
      "epoch": 0.4693333333333333,
      "grad_norm": 0.4297275245189667,
      "learning_rate": 0.00016871696413757142,
      "loss": 1.3919,
      "step": 6600
    },
    {
      "epoch": 0.47644444444444445,
      "grad_norm": 0.3511750102043152,
      "learning_rate": 0.0001682429069188651,
      "loss": 1.3714,
      "step": 6700
    },
    {
      "epoch": 0.48355555555555557,
      "grad_norm": 0.4192405343055725,
      "learning_rate": 0.00016776884970015884,
      "loss": 1.4071,
      "step": 6800
    },
    {
      "epoch": 0.49066666666666664,
      "grad_norm": 0.4141962230205536,
      "learning_rate": 0.00016729479248145252,
      "loss": 1.3504,
      "step": 6900
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.41438642144203186,
      "learning_rate": 0.00016682073526274623,
      "loss": 1.3606,
      "step": 7000
    },
    {
      "epoch": 0.49777777777777776,
      "eval_loss": 1.3368860483169556,
      "eval_runtime": 258.4709,
      "eval_samples_per_second": 193.445,
      "eval_steps_per_second": 12.09,
      "step": 7000
    },
    {
      "epoch": 0.5048888888888889,
      "grad_norm": 0.408610463142395,
      "learning_rate": 0.0001663466780440399,
      "loss": 1.3565,
      "step": 7100
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.37263786792755127,
      "learning_rate": 0.00016587262082533365,
      "loss": 1.3271,
      "step": 7200
    },
    {
      "epoch": 0.5191111111111111,
      "grad_norm": 0.37014710903167725,
      "learning_rate": 0.00016539856360662733,
      "loss": 1.3629,
      "step": 7300
    },
    {
      "epoch": 0.5262222222222223,
      "grad_norm": 0.4270035922527313,
      "learning_rate": 0.00016492450638792104,
      "loss": 1.3343,
      "step": 7400
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.31023433804512024,
      "learning_rate": 0.00016445044916921472,
      "loss": 1.3247,
      "step": 7500
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 1.3355512619018555,
      "eval_runtime": 258.937,
      "eval_samples_per_second": 193.097,
      "eval_steps_per_second": 12.069,
      "step": 7500
    },
    {
      "epoch": 0.5404444444444444,
      "grad_norm": 0.4043787121772766,
      "learning_rate": 0.00016397639195050843,
      "loss": 1.3474,
      "step": 7600
    },
    {
      "epoch": 0.5475555555555556,
      "grad_norm": 0.371268630027771,
      "learning_rate": 0.00016350233473180214,
      "loss": 1.3436,
      "step": 7700
    },
    {
      "epoch": 0.5546666666666666,
      "grad_norm": 0.4546333849430084,
      "learning_rate": 0.00016302827751309585,
      "loss": 1.3623,
      "step": 7800
    },
    {
      "epoch": 0.5617777777777778,
      "grad_norm": 0.41289222240448,
      "learning_rate": 0.00016255422029438953,
      "loss": 1.3468,
      "step": 7900
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.4036211371421814,
      "learning_rate": 0.00016208016307568324,
      "loss": 1.3566,
      "step": 8000
    },
    {
      "epoch": 0.5688888888888889,
      "eval_loss": 1.334068775177002,
      "eval_runtime": 259.5017,
      "eval_samples_per_second": 192.677,
      "eval_steps_per_second": 12.042,
      "step": 8000
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.4037942886352539,
      "learning_rate": 0.00016160610585697695,
      "loss": 1.363,
      "step": 8100
    },
    {
      "epoch": 0.5831111111111111,
      "grad_norm": 0.5979922413825989,
      "learning_rate": 0.00016113204863827066,
      "loss": 1.3735,
      "step": 8200
    },
    {
      "epoch": 0.5902222222222222,
      "grad_norm": 0.39674848318099976,
      "learning_rate": 0.00016065799141956434,
      "loss": 1.3575,
      "step": 8300
    },
    {
      "epoch": 0.5973333333333334,
      "grad_norm": 0.4626960754394531,
      "learning_rate": 0.00016018393420085805,
      "loss": 1.3855,
      "step": 8400
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.36915451288223267,
      "learning_rate": 0.00015970987698215176,
      "loss": 1.3519,
      "step": 8500
    },
    {
      "epoch": 0.6044444444444445,
      "eval_loss": 1.3329490423202515,
      "eval_runtime": 258.4681,
      "eval_samples_per_second": 193.447,
      "eval_steps_per_second": 12.09,
      "step": 8500
    },
    {
      "epoch": 0.6115555555555555,
      "grad_norm": 0.5446401238441467,
      "learning_rate": 0.00015923581976344547,
      "loss": 1.367,
      "step": 8600
    },
    {
      "epoch": 0.6186666666666667,
      "grad_norm": 0.4416266083717346,
      "learning_rate": 0.00015876176254473915,
      "loss": 1.3669,
      "step": 8700
    },
    {
      "epoch": 0.6257777777777778,
      "grad_norm": 0.4913879334926605,
      "learning_rate": 0.00015828770532603286,
      "loss": 1.3421,
      "step": 8800
    },
    {
      "epoch": 0.6328888888888888,
      "grad_norm": 0.4368191957473755,
      "learning_rate": 0.00015781364810732657,
      "loss": 1.3641,
      "step": 8900
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4629287123680115,
      "learning_rate": 0.00015733959088862028,
      "loss": 1.3368,
      "step": 9000
    },
    {
      "epoch": 0.64,
      "eval_loss": 1.3322514295578003,
      "eval_runtime": 258.9256,
      "eval_samples_per_second": 193.106,
      "eval_steps_per_second": 12.069,
      "step": 9000
    },
    {
      "epoch": 0.6471111111111111,
      "grad_norm": 0.43163588643074036,
      "learning_rate": 0.00015686553366991396,
      "loss": 1.399,
      "step": 9100
    },
    {
      "epoch": 0.6542222222222223,
      "grad_norm": 0.3461313843727112,
      "learning_rate": 0.00015639147645120767,
      "loss": 1.3394,
      "step": 9200
    },
    {
      "epoch": 0.6613333333333333,
      "grad_norm": 0.39415374398231506,
      "learning_rate": 0.00015591741923250135,
      "loss": 1.3348,
      "step": 9300
    },
    {
      "epoch": 0.6684444444444444,
      "grad_norm": 0.3431917130947113,
      "learning_rate": 0.0001554433620137951,
      "loss": 1.363,
      "step": 9400
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.39267581701278687,
      "learning_rate": 0.00015496930479508877,
      "loss": 1.3429,
      "step": 9500
    },
    {
      "epoch": 0.6755555555555556,
      "eval_loss": 1.3312348127365112,
      "eval_runtime": 258.6018,
      "eval_samples_per_second": 193.347,
      "eval_steps_per_second": 12.084,
      "step": 9500
    },
    {
      "epoch": 0.6826666666666666,
      "grad_norm": 0.4003105163574219,
      "learning_rate": 0.00015449524757638248,
      "loss": 1.3767,
      "step": 9600
    },
    {
      "epoch": 0.6897777777777778,
      "grad_norm": 0.4150460958480835,
      "learning_rate": 0.00015402119035767616,
      "loss": 1.3833,
      "step": 9700
    },
    {
      "epoch": 0.6968888888888889,
      "grad_norm": 0.4023710787296295,
      "learning_rate": 0.0001535471331389699,
      "loss": 1.3767,
      "step": 9800
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.37460947036743164,
      "learning_rate": 0.00015307307592026358,
      "loss": 1.3375,
      "step": 9900
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.36939892172813416,
      "learning_rate": 0.0001525990187015573,
      "loss": 1.3353,
      "step": 10000
    },
    {
      "epoch": 0.7111111111111111,
      "eval_loss": 1.33056640625,
      "eval_runtime": 258.8345,
      "eval_samples_per_second": 193.174,
      "eval_steps_per_second": 12.073,
      "step": 10000
    },
    {
      "epoch": 0.7182222222222222,
      "grad_norm": 0.4678374230861664,
      "learning_rate": 0.00015212496148285097,
      "loss": 1.3519,
      "step": 10100
    },
    {
      "epoch": 0.7253333333333334,
      "grad_norm": 0.402208149433136,
      "learning_rate": 0.0001516509042641447,
      "loss": 1.3267,
      "step": 10200
    },
    {
      "epoch": 0.7324444444444445,
      "grad_norm": 0.317628413438797,
      "learning_rate": 0.0001511768470454384,
      "loss": 1.3846,
      "step": 10300
    },
    {
      "epoch": 0.7395555555555555,
      "grad_norm": 0.3739531636238098,
      "learning_rate": 0.0001507027898267321,
      "loss": 1.3414,
      "step": 10400
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.4378884434700012,
      "learning_rate": 0.00015022873260802578,
      "loss": 1.3726,
      "step": 10500
    },
    {
      "epoch": 0.7466666666666667,
      "eval_loss": 1.3297441005706787,
      "eval_runtime": 258.9842,
      "eval_samples_per_second": 193.062,
      "eval_steps_per_second": 12.066,
      "step": 10500
    },
    {
      "epoch": 0.7537777777777778,
      "grad_norm": 0.41192370653152466,
      "learning_rate": 0.0001497546753893195,
      "loss": 1.3766,
      "step": 10600
    },
    {
      "epoch": 0.7608888888888888,
      "grad_norm": 0.47547343373298645,
      "learning_rate": 0.0001492806181706132,
      "loss": 1.3815,
      "step": 10700
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.37528544664382935,
      "learning_rate": 0.0001488065609519069,
      "loss": 1.3419,
      "step": 10800
    },
    {
      "epoch": 0.7751111111111111,
      "grad_norm": 0.4214073121547699,
      "learning_rate": 0.0001483325037332006,
      "loss": 1.366,
      "step": 10900
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.5504201650619507,
      "learning_rate": 0.0001478584465144943,
      "loss": 1.3569,
      "step": 11000
    },
    {
      "epoch": 0.7822222222222223,
      "eval_loss": 1.328680157661438,
      "eval_runtime": 259.8208,
      "eval_samples_per_second": 192.44,
      "eval_steps_per_second": 12.028,
      "step": 11000
    },
    {
      "epoch": 0.7893333333333333,
      "grad_norm": 0.4480074346065521,
      "learning_rate": 0.000147384389295788,
      "loss": 1.3865,
      "step": 11100
    },
    {
      "epoch": 0.7964444444444444,
      "grad_norm": 0.38815838098526,
      "learning_rate": 0.00014691033207708172,
      "loss": 1.3467,
      "step": 11200
    },
    {
      "epoch": 0.8035555555555556,
      "grad_norm": 0.43397313356399536,
      "learning_rate": 0.0001464362748583754,
      "loss": 1.3383,
      "step": 11300
    },
    {
      "epoch": 0.8106666666666666,
      "grad_norm": 0.4592589735984802,
      "learning_rate": 0.00014596221763966911,
      "loss": 1.3482,
      "step": 11400
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.42579618096351624,
      "learning_rate": 0.00014548816042096282,
      "loss": 1.3585,
      "step": 11500
    },
    {
      "epoch": 0.8177777777777778,
      "eval_loss": 1.3281033039093018,
      "eval_runtime": 259.5297,
      "eval_samples_per_second": 192.656,
      "eval_steps_per_second": 12.041,
      "step": 11500
    },
    {
      "epoch": 0.8248888888888889,
      "grad_norm": 0.4888402223587036,
      "learning_rate": 0.00014501410320225653,
      "loss": 1.3897,
      "step": 11600
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.3735975921154022,
      "learning_rate": 0.00014454004598355021,
      "loss": 1.3291,
      "step": 11700
    },
    {
      "epoch": 0.8391111111111111,
      "grad_norm": 0.4817737936973572,
      "learning_rate": 0.00014406598876484392,
      "loss": 1.3288,
      "step": 11800
    },
    {
      "epoch": 0.8462222222222222,
      "grad_norm": 0.3484348952770233,
      "learning_rate": 0.0001435919315461376,
      "loss": 1.3312,
      "step": 11900
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.5045949816703796,
      "learning_rate": 0.00014311787432743134,
      "loss": 1.3506,
      "step": 12000
    },
    {
      "epoch": 0.8533333333333334,
      "eval_loss": 1.3277992010116577,
      "eval_runtime": 258.3726,
      "eval_samples_per_second": 193.519,
      "eval_steps_per_second": 12.095,
      "step": 12000
    },
    {
      "epoch": 0.8604444444444445,
      "grad_norm": 0.42611512541770935,
      "learning_rate": 0.00014264381710872502,
      "loss": 1.3698,
      "step": 12100
    },
    {
      "epoch": 0.8675555555555555,
      "grad_norm": 0.4535831809043884,
      "learning_rate": 0.00014216975989001873,
      "loss": 1.3282,
      "step": 12200
    },
    {
      "epoch": 0.8746666666666667,
      "grad_norm": 0.3996088206768036,
      "learning_rate": 0.00014169570267131242,
      "loss": 1.3421,
      "step": 12300
    },
    {
      "epoch": 0.8817777777777778,
      "grad_norm": 0.3279254734516144,
      "learning_rate": 0.00014122164545260615,
      "loss": 1.3472,
      "step": 12400
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.415860116481781,
      "learning_rate": 0.00014074758823389984,
      "loss": 1.3538,
      "step": 12500
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 1.3264182806015015,
      "eval_runtime": 258.4779,
      "eval_samples_per_second": 193.44,
      "eval_steps_per_second": 12.09,
      "step": 12500
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.4397335350513458,
      "learning_rate": 0.00014027353101519354,
      "loss": 1.3822,
      "step": 12600
    },
    {
      "epoch": 0.9031111111111111,
      "grad_norm": 0.44722017645835876,
      "learning_rate": 0.00013979947379648723,
      "loss": 1.3536,
      "step": 12700
    },
    {
      "epoch": 0.9102222222222223,
      "grad_norm": 0.4308244287967682,
      "learning_rate": 0.00013932541657778096,
      "loss": 1.3642,
      "step": 12800
    },
    {
      "epoch": 0.9173333333333333,
      "grad_norm": 0.4764508903026581,
      "learning_rate": 0.00013885135935907465,
      "loss": 1.3429,
      "step": 12900
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.48360294103622437,
      "learning_rate": 0.00013837730214036835,
      "loss": 1.344,
      "step": 13000
    },
    {
      "epoch": 0.9244444444444444,
      "eval_loss": 1.3256444931030273,
      "eval_runtime": 257.9816,
      "eval_samples_per_second": 193.812,
      "eval_steps_per_second": 12.113,
      "step": 13000
    },
    {
      "epoch": 0.9315555555555556,
      "grad_norm": 0.5750572085380554,
      "learning_rate": 0.00013790324492166204,
      "loss": 1.3272,
      "step": 13100
    },
    {
      "epoch": 0.9386666666666666,
      "grad_norm": 0.42182084918022156,
      "learning_rate": 0.00013742918770295577,
      "loss": 1.3694,
      "step": 13200
    },
    {
      "epoch": 0.9457777777777778,
      "grad_norm": 0.391769677400589,
      "learning_rate": 0.00013695513048424946,
      "loss": 1.3678,
      "step": 13300
    },
    {
      "epoch": 0.9528888888888889,
      "grad_norm": 0.4223646819591522,
      "learning_rate": 0.00013648107326554316,
      "loss": 1.3457,
      "step": 13400
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.36660313606262207,
      "learning_rate": 0.00013600701604683685,
      "loss": 1.3149,
      "step": 13500
    },
    {
      "epoch": 0.96,
      "eval_loss": 1.3249759674072266,
      "eval_runtime": 257.6072,
      "eval_samples_per_second": 194.094,
      "eval_steps_per_second": 12.131,
      "step": 13500
    },
    {
      "epoch": 0.9671111111111111,
      "grad_norm": 0.48319733142852783,
      "learning_rate": 0.00013553295882813056,
      "loss": 1.3383,
      "step": 13600
    },
    {
      "epoch": 0.9742222222222222,
      "grad_norm": 0.39694270491600037,
      "learning_rate": 0.00013505890160942427,
      "loss": 1.3242,
      "step": 13700
    },
    {
      "epoch": 0.9813333333333333,
      "grad_norm": 0.41705039143562317,
      "learning_rate": 0.00013458484439071798,
      "loss": 1.3662,
      "step": 13800
    },
    {
      "epoch": 0.9884444444444445,
      "grad_norm": 0.4763980209827423,
      "learning_rate": 0.00013411078717201166,
      "loss": 1.3418,
      "step": 13900
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 0.3785812258720398,
      "learning_rate": 0.00013363672995330537,
      "loss": 1.366,
      "step": 14000
    },
    {
      "epoch": 0.9955555555555555,
      "eval_loss": 1.3248506784439087,
      "eval_runtime": 257.9344,
      "eval_samples_per_second": 193.848,
      "eval_steps_per_second": 12.115,
      "step": 14000
    },
    {
      "epoch": 1.002631111111111,
      "grad_norm": 0.433147132396698,
      "learning_rate": 0.00013316267273459908,
      "loss": 1.3235,
      "step": 14100
    },
    {
      "epoch": 1.0097422222222223,
      "grad_norm": 0.45159420371055603,
      "learning_rate": 0.00013268861551589279,
      "loss": 1.3082,
      "step": 14200
    },
    {
      "epoch": 1.0168533333333334,
      "grad_norm": 0.44161760807037354,
      "learning_rate": 0.00013221455829718647,
      "loss": 1.332,
      "step": 14300
    },
    {
      "epoch": 1.0239644444444445,
      "grad_norm": 0.38501155376434326,
      "learning_rate": 0.00013174050107848018,
      "loss": 1.3261,
      "step": 14400
    },
    {
      "epoch": 1.0310755555555555,
      "grad_norm": 0.5018690228462219,
      "learning_rate": 0.00013126644385977389,
      "loss": 1.284,
      "step": 14500
    },
    {
      "epoch": 1.0310755555555555,
      "eval_loss": 1.3256193399429321,
      "eval_runtime": 260.0867,
      "eval_samples_per_second": 192.244,
      "eval_steps_per_second": 12.015,
      "step": 14500
    },
    {
      "epoch": 1.0381866666666666,
      "grad_norm": 0.4655291438102722,
      "learning_rate": 0.0001307923866410676,
      "loss": 1.2845,
      "step": 14600
    },
    {
      "epoch": 1.0452977777777779,
      "grad_norm": 0.376009464263916,
      "learning_rate": 0.00013031832942236128,
      "loss": 1.2849,
      "step": 14700
    },
    {
      "epoch": 1.052408888888889,
      "grad_norm": 0.4368228018283844,
      "learning_rate": 0.000129844272203655,
      "loss": 1.3243,
      "step": 14800
    },
    {
      "epoch": 1.05952,
      "grad_norm": 0.4307501018047333,
      "learning_rate": 0.00012937021498494867,
      "loss": 1.297,
      "step": 14900
    },
    {
      "epoch": 1.066631111111111,
      "grad_norm": 0.5246236324310303,
      "learning_rate": 0.0001288961577662424,
      "loss": 1.29,
      "step": 15000
    },
    {
      "epoch": 1.066631111111111,
      "eval_loss": 1.3245848417282104,
      "eval_runtime": 259.7684,
      "eval_samples_per_second": 192.479,
      "eval_steps_per_second": 12.03,
      "step": 15000
    },
    {
      "epoch": 1.0737422222222222,
      "grad_norm": 0.4389384984970093,
      "learning_rate": 0.0001284221005475361,
      "loss": 1.3186,
      "step": 15100
    },
    {
      "epoch": 1.0808533333333332,
      "grad_norm": 0.46627679467201233,
      "learning_rate": 0.0001279480433288298,
      "loss": 1.3196,
      "step": 15200
    },
    {
      "epoch": 1.0879644444444445,
      "grad_norm": 0.44632676243782043,
      "learning_rate": 0.00012747398611012348,
      "loss": 1.2963,
      "step": 15300
    },
    {
      "epoch": 1.0950755555555556,
      "grad_norm": 0.45259472727775574,
      "learning_rate": 0.00012699992889141722,
      "loss": 1.311,
      "step": 15400
    },
    {
      "epoch": 1.1021866666666666,
      "grad_norm": 0.4059620201587677,
      "learning_rate": 0.0001265258716727109,
      "loss": 1.3004,
      "step": 15500
    },
    {
      "epoch": 1.1021866666666666,
      "eval_loss": 1.325277328491211,
      "eval_runtime": 258.7467,
      "eval_samples_per_second": 193.239,
      "eval_steps_per_second": 12.077,
      "step": 15500
    },
    {
      "epoch": 1.1092977777777777,
      "grad_norm": 0.5033121705055237,
      "learning_rate": 0.0001260518144540046,
      "loss": 1.314,
      "step": 15600
    },
    {
      "epoch": 1.116408888888889,
      "grad_norm": 0.4128105640411377,
      "learning_rate": 0.0001255777572352983,
      "loss": 1.3163,
      "step": 15700
    },
    {
      "epoch": 1.12352,
      "grad_norm": 0.3967747390270233,
      "learning_rate": 0.00012510370001659203,
      "loss": 1.3257,
      "step": 15800
    },
    {
      "epoch": 1.1306311111111111,
      "grad_norm": 0.4836679995059967,
      "learning_rate": 0.0001246296427978857,
      "loss": 1.293,
      "step": 15900
    },
    {
      "epoch": 1.1377422222222222,
      "grad_norm": 0.4330699145793915,
      "learning_rate": 0.00012415558557917942,
      "loss": 1.2986,
      "step": 16000
    },
    {
      "epoch": 1.1377422222222222,
      "eval_loss": 1.3252118825912476,
      "eval_runtime": 257.4444,
      "eval_samples_per_second": 194.217,
      "eval_steps_per_second": 12.139,
      "step": 16000
    },
    {
      "epoch": 1.1448533333333333,
      "grad_norm": 0.4693004786968231,
      "learning_rate": 0.0001236815283604731,
      "loss": 1.3068,
      "step": 16100
    },
    {
      "epoch": 1.1519644444444443,
      "grad_norm": 0.48136600852012634,
      "learning_rate": 0.00012320747114176684,
      "loss": 1.3025,
      "step": 16200
    },
    {
      "epoch": 1.1590755555555556,
      "grad_norm": 0.4262239336967468,
      "learning_rate": 0.00012273341392306052,
      "loss": 1.3118,
      "step": 16300
    },
    {
      "epoch": 1.1661866666666667,
      "grad_norm": 0.4800594747066498,
      "learning_rate": 0.00012225935670435423,
      "loss": 1.2859,
      "step": 16400
    },
    {
      "epoch": 1.1732977777777778,
      "grad_norm": 0.4562538266181946,
      "learning_rate": 0.00012178529948564792,
      "loss": 1.3084,
      "step": 16500
    },
    {
      "epoch": 1.1732977777777778,
      "eval_loss": 1.3244346380233765,
      "eval_runtime": 257.8602,
      "eval_samples_per_second": 193.904,
      "eval_steps_per_second": 12.119,
      "step": 16500
    },
    {
      "epoch": 1.1804088888888888,
      "grad_norm": 0.4733985662460327,
      "learning_rate": 0.00012131124226694162,
      "loss": 1.2511,
      "step": 16600
    },
    {
      "epoch": 1.18752,
      "grad_norm": 0.43428006768226624,
      "learning_rate": 0.00012083718504823533,
      "loss": 1.3239,
      "step": 16700
    },
    {
      "epoch": 1.1946311111111112,
      "grad_norm": 0.48264285922050476,
      "learning_rate": 0.00012036312782952904,
      "loss": 1.2768,
      "step": 16800
    },
    {
      "epoch": 1.2017422222222223,
      "grad_norm": 0.40165257453918457,
      "learning_rate": 0.00011988907061082273,
      "loss": 1.2968,
      "step": 16900
    },
    {
      "epoch": 1.2088533333333333,
      "grad_norm": 0.474851131439209,
      "learning_rate": 0.00011941501339211643,
      "loss": 1.2935,
      "step": 17000
    },
    {
      "epoch": 1.2088533333333333,
      "eval_loss": 1.3257142305374146,
      "eval_runtime": 257.7858,
      "eval_samples_per_second": 193.959,
      "eval_steps_per_second": 12.122,
      "step": 17000
    },
    {
      "epoch": 1.2159644444444444,
      "grad_norm": 0.5276919007301331,
      "learning_rate": 0.00011894095617341014,
      "loss": 1.2925,
      "step": 17100
    },
    {
      "epoch": 1.2230755555555555,
      "grad_norm": 0.5240753889083862,
      "learning_rate": 0.00011846689895470385,
      "loss": 1.3024,
      "step": 17200
    },
    {
      "epoch": 1.2301866666666668,
      "grad_norm": 0.7125281095504761,
      "learning_rate": 0.00011799284173599754,
      "loss": 1.3406,
      "step": 17300
    },
    {
      "epoch": 1.2372977777777778,
      "grad_norm": 0.4932386875152588,
      "learning_rate": 0.00011751878451729124,
      "loss": 1.3412,
      "step": 17400
    },
    {
      "epoch": 1.244408888888889,
      "grad_norm": 0.5707539319992065,
      "learning_rate": 0.00011704472729858495,
      "loss": 1.3283,
      "step": 17500
    },
    {
      "epoch": 1.244408888888889,
      "eval_loss": 1.3229210376739502,
      "eval_runtime": 257.3584,
      "eval_samples_per_second": 194.282,
      "eval_steps_per_second": 12.143,
      "step": 17500
    },
    {
      "epoch": 1.25152,
      "grad_norm": 0.4537358283996582,
      "learning_rate": 0.00011657067007987865,
      "loss": 1.3215,
      "step": 17600
    },
    {
      "epoch": 1.258631111111111,
      "grad_norm": 0.5055246353149414,
      "learning_rate": 0.00011609661286117235,
      "loss": 1.2655,
      "step": 17700
    },
    {
      "epoch": 1.2657422222222223,
      "grad_norm": 0.42021989822387695,
      "learning_rate": 0.00011562255564246605,
      "loss": 1.2912,
      "step": 17800
    },
    {
      "epoch": 1.2728533333333334,
      "grad_norm": 0.5493124723434448,
      "learning_rate": 0.00011514849842375975,
      "loss": 1.3265,
      "step": 17900
    },
    {
      "epoch": 1.2799644444444445,
      "grad_norm": 0.5160644054412842,
      "learning_rate": 0.00011467444120505346,
      "loss": 1.3626,
      "step": 18000
    },
    {
      "epoch": 1.2799644444444445,
      "eval_loss": 1.3231366872787476,
      "eval_runtime": 257.3493,
      "eval_samples_per_second": 194.288,
      "eval_steps_per_second": 12.143,
      "step": 18000
    },
    {
      "epoch": 1.2870755555555555,
      "grad_norm": 0.5485673546791077,
      "learning_rate": 0.00011420038398634717,
      "loss": 1.2673,
      "step": 18100
    },
    {
      "epoch": 1.2941866666666666,
      "grad_norm": 0.5110572576522827,
      "learning_rate": 0.00011372632676764086,
      "loss": 1.282,
      "step": 18200
    },
    {
      "epoch": 1.3012977777777777,
      "grad_norm": 0.49984386563301086,
      "learning_rate": 0.00011325226954893456,
      "loss": 1.3049,
      "step": 18300
    },
    {
      "epoch": 1.308408888888889,
      "grad_norm": 0.46275952458381653,
      "learning_rate": 0.00011277821233022827,
      "loss": 1.3042,
      "step": 18400
    },
    {
      "epoch": 1.31552,
      "grad_norm": 0.5243672132492065,
      "learning_rate": 0.00011230415511152198,
      "loss": 1.2845,
      "step": 18500
    },
    {
      "epoch": 1.31552,
      "eval_loss": 1.3242932558059692,
      "eval_runtime": 257.6831,
      "eval_samples_per_second": 194.037,
      "eval_steps_per_second": 12.127,
      "step": 18500
    },
    {
      "epoch": 1.322631111111111,
      "grad_norm": 0.5040819048881531,
      "learning_rate": 0.00011183009789281567,
      "loss": 1.3168,
      "step": 18600
    },
    {
      "epoch": 1.3297422222222222,
      "grad_norm": 0.5695377588272095,
      "learning_rate": 0.00011135604067410937,
      "loss": 1.2981,
      "step": 18700
    },
    {
      "epoch": 1.3368533333333334,
      "grad_norm": 0.5698492527008057,
      "learning_rate": 0.00011088198345540308,
      "loss": 1.3144,
      "step": 18800
    },
    {
      "epoch": 1.3439644444444445,
      "grad_norm": 0.46729910373687744,
      "learning_rate": 0.00011040792623669679,
      "loss": 1.2975,
      "step": 18900
    },
    {
      "epoch": 1.3510755555555556,
      "grad_norm": 0.697136402130127,
      "learning_rate": 0.00010993386901799048,
      "loss": 1.3249,
      "step": 19000
    },
    {
      "epoch": 1.3510755555555556,
      "eval_loss": 1.3224892616271973,
      "eval_runtime": 257.8978,
      "eval_samples_per_second": 193.875,
      "eval_steps_per_second": 12.117,
      "step": 19000
    },
    {
      "epoch": 1.3581866666666667,
      "grad_norm": 0.46426087617874146,
      "learning_rate": 0.00010945981179928418,
      "loss": 1.3078,
      "step": 19100
    },
    {
      "epoch": 1.3652977777777777,
      "grad_norm": 0.47721630334854126,
      "learning_rate": 0.00010898575458057787,
      "loss": 1.328,
      "step": 19200
    },
    {
      "epoch": 1.3724088888888888,
      "grad_norm": 0.5967345237731934,
      "learning_rate": 0.0001085116973618716,
      "loss": 1.3184,
      "step": 19300
    },
    {
      "epoch": 1.37952,
      "grad_norm": 0.5391672849655151,
      "learning_rate": 0.00010803764014316529,
      "loss": 1.3104,
      "step": 19400
    },
    {
      "epoch": 1.3866311111111111,
      "grad_norm": 0.5275498032569885,
      "learning_rate": 0.00010756358292445899,
      "loss": 1.2961,
      "step": 19500
    },
    {
      "epoch": 1.3866311111111111,
      "eval_loss": 1.3227912187576294,
      "eval_runtime": 257.5292,
      "eval_samples_per_second": 194.153,
      "eval_steps_per_second": 12.135,
      "step": 19500
    },
    {
      "epoch": 1.3937422222222222,
      "grad_norm": 0.4830627739429474,
      "learning_rate": 0.00010708952570575268,
      "loss": 1.3384,
      "step": 19600
    },
    {
      "epoch": 1.4008533333333333,
      "grad_norm": 0.5725870728492737,
      "learning_rate": 0.00010661546848704639,
      "loss": 1.32,
      "step": 19700
    },
    {
      "epoch": 1.4079644444444446,
      "grad_norm": 0.4692099094390869,
      "learning_rate": 0.0001061414112683401,
      "loss": 1.2804,
      "step": 19800
    },
    {
      "epoch": 1.4150755555555556,
      "grad_norm": 0.49841445684432983,
      "learning_rate": 0.0001056673540496338,
      "loss": 1.3008,
      "step": 19900
    },
    {
      "epoch": 1.4221866666666667,
      "grad_norm": 0.45155835151672363,
      "learning_rate": 0.0001051932968309275,
      "loss": 1.3265,
      "step": 20000
    },
    {
      "epoch": 1.4221866666666667,
      "eval_loss": 1.3219265937805176,
      "eval_runtime": 257.7536,
      "eval_samples_per_second": 193.984,
      "eval_steps_per_second": 12.124,
      "step": 20000
    },
    {
      "epoch": 1.4292977777777778,
      "grad_norm": 0.44203174114227295,
      "learning_rate": 0.0001047192396122212,
      "loss": 1.3135,
      "step": 20100
    },
    {
      "epoch": 1.4364088888888888,
      "grad_norm": 0.43839630484580994,
      "learning_rate": 0.00010424518239351491,
      "loss": 1.3066,
      "step": 20200
    },
    {
      "epoch": 1.44352,
      "grad_norm": 0.5477844476699829,
      "learning_rate": 0.00010377112517480861,
      "loss": 1.3141,
      "step": 20300
    },
    {
      "epoch": 1.450631111111111,
      "grad_norm": 0.4450700879096985,
      "learning_rate": 0.0001032970679561023,
      "loss": 1.2875,
      "step": 20400
    },
    {
      "epoch": 1.4577422222222223,
      "grad_norm": 0.5176002979278564,
      "learning_rate": 0.00010282301073739601,
      "loss": 1.3108,
      "step": 20500
    },
    {
      "epoch": 1.4577422222222223,
      "eval_loss": 1.3218883275985718,
      "eval_runtime": 257.5648,
      "eval_samples_per_second": 194.126,
      "eval_steps_per_second": 12.133,
      "step": 20500
    },
    {
      "epoch": 1.4648533333333333,
      "grad_norm": 0.5012864470481873,
      "learning_rate": 0.00010234895351868972,
      "loss": 1.3109,
      "step": 20600
    },
    {
      "epoch": 1.4719644444444444,
      "grad_norm": 0.5539711117744446,
      "learning_rate": 0.00010187489629998342,
      "loss": 1.291,
      "step": 20700
    },
    {
      "epoch": 1.4790755555555555,
      "grad_norm": 0.5160878300666809,
      "learning_rate": 0.00010140083908127711,
      "loss": 1.3018,
      "step": 20800
    },
    {
      "epoch": 1.4861866666666668,
      "grad_norm": 0.5080710649490356,
      "learning_rate": 0.00010092678186257081,
      "loss": 1.3263,
      "step": 20900
    },
    {
      "epoch": 1.4932977777777778,
      "grad_norm": 0.447517454624176,
      "learning_rate": 0.00010045272464386453,
      "loss": 1.3183,
      "step": 21000
    },
    {
      "epoch": 1.4932977777777778,
      "eval_loss": 1.321333885192871,
      "eval_runtime": 257.482,
      "eval_samples_per_second": 194.188,
      "eval_steps_per_second": 12.137,
      "step": 21000
    },
    {
      "epoch": 1.500408888888889,
      "grad_norm": 0.5588226318359375,
      "learning_rate": 9.997866742515823e-05,
      "loss": 1.3037,
      "step": 21100
    },
    {
      "epoch": 1.50752,
      "grad_norm": 0.4397079348564148,
      "learning_rate": 9.950461020645192e-05,
      "loss": 1.3151,
      "step": 21200
    },
    {
      "epoch": 1.514631111111111,
      "grad_norm": 0.542417585849762,
      "learning_rate": 9.903055298774563e-05,
      "loss": 1.3283,
      "step": 21300
    },
    {
      "epoch": 1.521742222222222,
      "grad_norm": 0.6296840310096741,
      "learning_rate": 9.855649576903933e-05,
      "loss": 1.3263,
      "step": 21400
    },
    {
      "epoch": 1.5288533333333332,
      "grad_norm": 0.6152918934822083,
      "learning_rate": 9.808243855033304e-05,
      "loss": 1.3326,
      "step": 21500
    },
    {
      "epoch": 1.5288533333333332,
      "eval_loss": 1.3204790353775024,
      "eval_runtime": 257.3051,
      "eval_samples_per_second": 194.322,
      "eval_steps_per_second": 12.145,
      "step": 21500
    },
    {
      "epoch": 1.5359644444444445,
      "grad_norm": 0.48471522331237793,
      "learning_rate": 9.760838133162673e-05,
      "loss": 1.2971,
      "step": 21600
    },
    {
      "epoch": 1.5430755555555555,
      "grad_norm": 0.5076435208320618,
      "learning_rate": 9.713432411292044e-05,
      "loss": 1.3234,
      "step": 21700
    },
    {
      "epoch": 1.5501866666666668,
      "grad_norm": 0.47429561614990234,
      "learning_rate": 9.666026689421414e-05,
      "loss": 1.2994,
      "step": 21800
    },
    {
      "epoch": 1.557297777777778,
      "grad_norm": 0.478588342666626,
      "learning_rate": 9.618620967550785e-05,
      "loss": 1.3318,
      "step": 21900
    },
    {
      "epoch": 1.564408888888889,
      "grad_norm": 0.5736380219459534,
      "learning_rate": 9.571215245680154e-05,
      "loss": 1.2979,
      "step": 22000
    },
    {
      "epoch": 1.564408888888889,
      "eval_loss": 1.3205633163452148,
      "eval_runtime": 257.7592,
      "eval_samples_per_second": 193.979,
      "eval_steps_per_second": 12.124,
      "step": 22000
    },
    {
      "epoch": 1.57152,
      "grad_norm": 0.5536991953849792,
      "learning_rate": 9.523809523809524e-05,
      "loss": 1.3267,
      "step": 22100
    },
    {
      "epoch": 1.578631111111111,
      "grad_norm": 0.5552898049354553,
      "learning_rate": 9.476403801938895e-05,
      "loss": 1.3118,
      "step": 22200
    },
    {
      "epoch": 1.5857422222222222,
      "grad_norm": 0.5373122096061707,
      "learning_rate": 9.428998080068265e-05,
      "loss": 1.3141,
      "step": 22300
    },
    {
      "epoch": 1.5928533333333332,
      "grad_norm": 0.5909503102302551,
      "learning_rate": 9.381592358197636e-05,
      "loss": 1.3209,
      "step": 22400
    },
    {
      "epoch": 1.5999644444444443,
      "grad_norm": 0.5285933017730713,
      "learning_rate": 9.334186636327005e-05,
      "loss": 1.3043,
      "step": 22500
    },
    {
      "epoch": 1.5999644444444443,
      "eval_loss": 1.3194912672042847,
      "eval_runtime": 257.3914,
      "eval_samples_per_second": 194.257,
      "eval_steps_per_second": 12.141,
      "step": 22500
    },
    {
      "epoch": 1.6070755555555556,
      "grad_norm": 0.600248396396637,
      "learning_rate": 9.286780914456376e-05,
      "loss": 1.3262,
      "step": 22600
    },
    {
      "epoch": 1.6141866666666667,
      "grad_norm": 0.4516781270503998,
      "learning_rate": 9.239375192585746e-05,
      "loss": 1.2943,
      "step": 22700
    },
    {
      "epoch": 1.6212977777777777,
      "grad_norm": 0.46884918212890625,
      "learning_rate": 9.191969470715117e-05,
      "loss": 1.3095,
      "step": 22800
    },
    {
      "epoch": 1.628408888888889,
      "grad_norm": 0.5258234143257141,
      "learning_rate": 9.144563748844486e-05,
      "loss": 1.283,
      "step": 22900
    },
    {
      "epoch": 1.63552,
      "grad_norm": 0.45613956451416016,
      "learning_rate": 9.097158026973857e-05,
      "loss": 1.3386,
      "step": 23000
    },
    {
      "epoch": 1.63552,
      "eval_loss": 1.3186709880828857,
      "eval_runtime": 257.6582,
      "eval_samples_per_second": 194.056,
      "eval_steps_per_second": 12.128,
      "step": 23000
    },
    {
      "epoch": 1.6426311111111112,
      "grad_norm": 0.5557495355606079,
      "learning_rate": 9.049752305103227e-05,
      "loss": 1.3091,
      "step": 23100
    },
    {
      "epoch": 1.6497422222222222,
      "grad_norm": 0.4864502251148224,
      "learning_rate": 9.002346583232598e-05,
      "loss": 1.3376,
      "step": 23200
    },
    {
      "epoch": 1.6568533333333333,
      "grad_norm": 0.5933363437652588,
      "learning_rate": 8.954940861361967e-05,
      "loss": 1.3074,
      "step": 23300
    },
    {
      "epoch": 1.6639644444444444,
      "grad_norm": 0.49277234077453613,
      "learning_rate": 8.907535139491338e-05,
      "loss": 1.316,
      "step": 23400
    },
    {
      "epoch": 1.6710755555555554,
      "grad_norm": 0.6081154346466064,
      "learning_rate": 8.860129417620708e-05,
      "loss": 1.2849,
      "step": 23500
    },
    {
      "epoch": 1.6710755555555554,
      "eval_loss": 1.3190231323242188,
      "eval_runtime": 257.3971,
      "eval_samples_per_second": 194.252,
      "eval_steps_per_second": 12.141,
      "step": 23500
    },
    {
      "epoch": 1.6781866666666667,
      "grad_norm": 0.5365684628486633,
      "learning_rate": 8.812723695750077e-05,
      "loss": 1.3238,
      "step": 23600
    },
    {
      "epoch": 1.6852977777777778,
      "grad_norm": 0.5710518956184387,
      "learning_rate": 8.765317973879448e-05,
      "loss": 1.3349,
      "step": 23700
    },
    {
      "epoch": 1.6924088888888889,
      "grad_norm": 0.5461223721504211,
      "learning_rate": 8.717912252008818e-05,
      "loss": 1.2928,
      "step": 23800
    },
    {
      "epoch": 1.6995200000000001,
      "grad_norm": 0.5076824426651001,
      "learning_rate": 8.670506530138189e-05,
      "loss": 1.292,
      "step": 23900
    },
    {
      "epoch": 1.7066311111111112,
      "grad_norm": 0.4600980877876282,
      "learning_rate": 8.623100808267558e-05,
      "loss": 1.3058,
      "step": 24000
    },
    {
      "epoch": 1.7066311111111112,
      "eval_loss": 1.3185646533966064,
      "eval_runtime": 257.6392,
      "eval_samples_per_second": 194.07,
      "eval_steps_per_second": 12.129,
      "step": 24000
    },
    {
      "epoch": 1.7137422222222223,
      "grad_norm": 0.45917004346847534,
      "learning_rate": 8.575695086396929e-05,
      "loss": 1.2699,
      "step": 24100
    },
    {
      "epoch": 1.7208533333333333,
      "grad_norm": 0.47817814350128174,
      "learning_rate": 8.528289364526299e-05,
      "loss": 1.3166,
      "step": 24200
    },
    {
      "epoch": 1.7279644444444444,
      "grad_norm": 0.4736846387386322,
      "learning_rate": 8.48088364265567e-05,
      "loss": 1.295,
      "step": 24300
    },
    {
      "epoch": 1.7350755555555555,
      "grad_norm": 0.6185967326164246,
      "learning_rate": 8.433477920785039e-05,
      "loss": 1.3141,
      "step": 24400
    },
    {
      "epoch": 1.7421866666666666,
      "grad_norm": 0.5649062395095825,
      "learning_rate": 8.38607219891441e-05,
      "loss": 1.2933,
      "step": 24500
    },
    {
      "epoch": 1.7421866666666666,
      "eval_loss": 1.3176307678222656,
      "eval_runtime": 257.3721,
      "eval_samples_per_second": 194.271,
      "eval_steps_per_second": 12.142,
      "step": 24500
    },
    {
      "epoch": 1.7492977777777776,
      "grad_norm": 0.6260524988174438,
      "learning_rate": 8.33866647704378e-05,
      "loss": 1.2803,
      "step": 24600
    },
    {
      "epoch": 1.756408888888889,
      "grad_norm": 0.6107718348503113,
      "learning_rate": 8.291260755173151e-05,
      "loss": 1.3069,
      "step": 24700
    },
    {
      "epoch": 1.76352,
      "grad_norm": 0.5021238327026367,
      "learning_rate": 8.24385503330252e-05,
      "loss": 1.2908,
      "step": 24800
    },
    {
      "epoch": 1.7706311111111113,
      "grad_norm": 0.5993924736976624,
      "learning_rate": 8.196449311431891e-05,
      "loss": 1.3033,
      "step": 24900
    },
    {
      "epoch": 1.7777422222222223,
      "grad_norm": 0.539234459400177,
      "learning_rate": 8.149043589561261e-05,
      "loss": 1.2903,
      "step": 25000
    },
    {
      "epoch": 1.7777422222222223,
      "eval_loss": 1.3182754516601562,
      "eval_runtime": 257.3773,
      "eval_samples_per_second": 194.267,
      "eval_steps_per_second": 12.142,
      "step": 25000
    },
    {
      "epoch": 1.7848533333333334,
      "grad_norm": 0.5921714901924133,
      "learning_rate": 8.10163786769063e-05,
      "loss": 1.3247,
      "step": 25100
    },
    {
      "epoch": 1.7919644444444445,
      "grad_norm": 0.5368619561195374,
      "learning_rate": 8.054232145820001e-05,
      "loss": 1.3058,
      "step": 25200
    },
    {
      "epoch": 1.7990755555555555,
      "grad_norm": 0.4584469795227051,
      "learning_rate": 8.006826423949371e-05,
      "loss": 1.3064,
      "step": 25300
    },
    {
      "epoch": 1.8061866666666666,
      "grad_norm": 0.5274226665496826,
      "learning_rate": 7.959420702078742e-05,
      "loss": 1.3629,
      "step": 25400
    },
    {
      "epoch": 1.8132977777777777,
      "grad_norm": 0.5360814929008484,
      "learning_rate": 7.912014980208111e-05,
      "loss": 1.3264,
      "step": 25500
    },
    {
      "epoch": 1.8132977777777777,
      "eval_loss": 1.318132758140564,
      "eval_runtime": 257.6951,
      "eval_samples_per_second": 194.028,
      "eval_steps_per_second": 12.127,
      "step": 25500
    },
    {
      "epoch": 1.8204088888888887,
      "grad_norm": 0.610808253288269,
      "learning_rate": 7.864609258337482e-05,
      "loss": 1.3247,
      "step": 25600
    },
    {
      "epoch": 1.82752,
      "grad_norm": 0.4750231206417084,
      "learning_rate": 7.817203536466852e-05,
      "loss": 1.2854,
      "step": 25700
    },
    {
      "epoch": 1.834631111111111,
      "grad_norm": 0.4716953933238983,
      "learning_rate": 7.769797814596223e-05,
      "loss": 1.3019,
      "step": 25800
    },
    {
      "epoch": 1.8417422222222222,
      "grad_norm": 0.5340036153793335,
      "learning_rate": 7.722392092725592e-05,
      "loss": 1.2995,
      "step": 25900
    },
    {
      "epoch": 1.8488533333333335,
      "grad_norm": 0.4780287742614746,
      "learning_rate": 7.674986370854963e-05,
      "loss": 1.3147,
      "step": 26000
    },
    {
      "epoch": 1.8488533333333335,
      "eval_loss": 1.3166924715042114,
      "eval_runtime": 257.331,
      "eval_samples_per_second": 194.302,
      "eval_steps_per_second": 12.144,
      "step": 26000
    },
    {
      "epoch": 1.8559644444444445,
      "grad_norm": 0.5391697883605957,
      "learning_rate": 7.627580648984333e-05,
      "loss": 1.3229,
      "step": 26100
    },
    {
      "epoch": 1.8630755555555556,
      "grad_norm": 0.596415638923645,
      "learning_rate": 7.580174927113704e-05,
      "loss": 1.3161,
      "step": 26200
    },
    {
      "epoch": 1.8701866666666667,
      "grad_norm": 0.643619954586029,
      "learning_rate": 7.532769205243073e-05,
      "loss": 1.314,
      "step": 26300
    },
    {
      "epoch": 1.8772977777777777,
      "grad_norm": 0.5505822896957397,
      "learning_rate": 7.485363483372443e-05,
      "loss": 1.3229,
      "step": 26400
    },
    {
      "epoch": 1.8844088888888888,
      "grad_norm": 0.5058190226554871,
      "learning_rate": 7.437957761501814e-05,
      "loss": 1.287,
      "step": 26500
    },
    {
      "epoch": 1.8844088888888888,
      "eval_loss": 1.316733717918396,
      "eval_runtime": 257.3634,
      "eval_samples_per_second": 194.278,
      "eval_steps_per_second": 12.142,
      "step": 26500
    },
    {
      "epoch": 1.8915199999999999,
      "grad_norm": 0.570500373840332,
      "learning_rate": 7.390552039631184e-05,
      "loss": 1.2984,
      "step": 26600
    },
    {
      "epoch": 1.8986311111111112,
      "grad_norm": 0.5739282965660095,
      "learning_rate": 7.343146317760555e-05,
      "loss": 1.3178,
      "step": 26700
    },
    {
      "epoch": 1.9057422222222222,
      "grad_norm": 0.5237268209457397,
      "learning_rate": 7.295740595889924e-05,
      "loss": 1.2577,
      "step": 26800
    },
    {
      "epoch": 1.9128533333333333,
      "grad_norm": 0.448864221572876,
      "learning_rate": 7.248334874019295e-05,
      "loss": 1.2758,
      "step": 26900
    },
    {
      "epoch": 1.9199644444444446,
      "grad_norm": 0.46819233894348145,
      "learning_rate": 7.200929152148665e-05,
      "loss": 1.2875,
      "step": 27000
    },
    {
      "epoch": 1.9199644444444446,
      "eval_loss": 1.3160121440887451,
      "eval_runtime": 259.3951,
      "eval_samples_per_second": 192.756,
      "eval_steps_per_second": 12.047,
      "step": 27000
    },
    {
      "epoch": 1.9270755555555557,
      "grad_norm": 0.5268092751502991,
      "learning_rate": 7.153523430278036e-05,
      "loss": 1.2927,
      "step": 27100
    },
    {
      "epoch": 1.9341866666666667,
      "grad_norm": 0.4964086711406708,
      "learning_rate": 7.106117708407405e-05,
      "loss": 1.311,
      "step": 27200
    },
    {
      "epoch": 1.9412977777777778,
      "grad_norm": 0.5476360321044922,
      "learning_rate": 7.058711986536776e-05,
      "loss": 1.2863,
      "step": 27300
    },
    {
      "epoch": 1.9484088888888889,
      "grad_norm": 0.534563422203064,
      "learning_rate": 7.011306264666146e-05,
      "loss": 1.3091,
      "step": 27400
    },
    {
      "epoch": 1.95552,
      "grad_norm": 0.6540334224700928,
      "learning_rate": 6.963900542795517e-05,
      "loss": 1.3069,
      "step": 27500
    },
    {
      "epoch": 1.95552,
      "eval_loss": 1.3163862228393555,
      "eval_runtime": 259.4527,
      "eval_samples_per_second": 192.713,
      "eval_steps_per_second": 12.045,
      "step": 27500
    },
    {
      "epoch": 1.962631111111111,
      "grad_norm": 0.5778530240058899,
      "learning_rate": 6.916494820924886e-05,
      "loss": 1.3243,
      "step": 27600
    },
    {
      "epoch": 1.969742222222222,
      "grad_norm": 0.6228817701339722,
      "learning_rate": 6.869089099054257e-05,
      "loss": 1.3261,
      "step": 27700
    },
    {
      "epoch": 1.9768533333333334,
      "grad_norm": 0.4863548278808594,
      "learning_rate": 6.821683377183627e-05,
      "loss": 1.2936,
      "step": 27800
    },
    {
      "epoch": 1.9839644444444444,
      "grad_norm": 0.7293127179145813,
      "learning_rate": 6.774277655312996e-05,
      "loss": 1.3398,
      "step": 27900
    },
    {
      "epoch": 1.9910755555555557,
      "grad_norm": 0.4648377299308777,
      "learning_rate": 6.726871933442367e-05,
      "loss": 1.3519,
      "step": 28000
    },
    {
      "epoch": 1.9910755555555557,
      "eval_loss": 1.3149025440216064,
      "eval_runtime": 259.1659,
      "eval_samples_per_second": 192.927,
      "eval_steps_per_second": 12.058,
      "step": 28000
    }
  ],
  "logging_steps": 100,
  "max_steps": 42189,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.09160892834775e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
