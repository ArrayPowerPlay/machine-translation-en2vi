{
  "best_global_step": 22500,
  "best_metric": 1.1799790859222412,
  "best_model_checkpoint": "/kaggle/working/lora-vinai-vi2en/checkpoint-22500",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 22500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008888888888888889,
      "grad_norm": 0.36046138405799866,
      "learning_rate": 0.00019941333333333333,
      "loss": 1.2735,
      "step": 100
    },
    {
      "epoch": 0.017777777777777778,
      "grad_norm": 0.3706035315990448,
      "learning_rate": 0.00019882074074074074,
      "loss": 1.2429,
      "step": 200
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 0.3494557738304138,
      "learning_rate": 0.00019822814814814815,
      "loss": 1.2413,
      "step": 300
    },
    {
      "epoch": 0.035555555555555556,
      "grad_norm": 0.3517828583717346,
      "learning_rate": 0.00019763555555555557,
      "loss": 1.2374,
      "step": 400
    },
    {
      "epoch": 0.044444444444444446,
      "grad_norm": 0.38146665692329407,
      "learning_rate": 0.00019704296296296295,
      "loss": 1.2252,
      "step": 500
    },
    {
      "epoch": 0.044444444444444446,
      "eval_loss": 1.2128851413726807,
      "eval_runtime": 204.0306,
      "eval_samples_per_second": 196.049,
      "eval_steps_per_second": 12.253,
      "step": 500
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 0.4013132154941559,
      "learning_rate": 0.00019645037037037036,
      "loss": 1.2735,
      "step": 600
    },
    {
      "epoch": 0.06222222222222222,
      "grad_norm": 0.3087565302848816,
      "learning_rate": 0.00019585777777777778,
      "loss": 1.2636,
      "step": 700
    },
    {
      "epoch": 0.07111111111111111,
      "grad_norm": 0.3877301812171936,
      "learning_rate": 0.0001952651851851852,
      "loss": 1.2189,
      "step": 800
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.33537203073501587,
      "learning_rate": 0.0001946725925925926,
      "loss": 1.2466,
      "step": 900
    },
    {
      "epoch": 0.08888888888888889,
      "grad_norm": 0.34668540954589844,
      "learning_rate": 0.00019408,
      "loss": 1.2066,
      "step": 1000
    },
    {
      "epoch": 0.08888888888888889,
      "eval_loss": 1.2044926881790161,
      "eval_runtime": 204.0232,
      "eval_samples_per_second": 196.056,
      "eval_steps_per_second": 12.254,
      "step": 1000
    },
    {
      "epoch": 0.09777777777777778,
      "grad_norm": 0.39766767621040344,
      "learning_rate": 0.0001934874074074074,
      "loss": 1.2637,
      "step": 1100
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 0.3338300585746765,
      "learning_rate": 0.0001928948148148148,
      "loss": 1.222,
      "step": 1200
    },
    {
      "epoch": 0.11555555555555555,
      "grad_norm": 0.3165658712387085,
      "learning_rate": 0.00019230222222222222,
      "loss": 1.2469,
      "step": 1300
    },
    {
      "epoch": 0.12444444444444444,
      "grad_norm": 0.3706313669681549,
      "learning_rate": 0.00019170962962962963,
      "loss": 1.2297,
      "step": 1400
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.3570821285247803,
      "learning_rate": 0.00019111703703703705,
      "loss": 1.2243,
      "step": 1500
    },
    {
      "epoch": 0.13333333333333333,
      "eval_loss": 1.2020015716552734,
      "eval_runtime": 204.2915,
      "eval_samples_per_second": 195.799,
      "eval_steps_per_second": 12.237,
      "step": 1500
    },
    {
      "epoch": 0.14222222222222222,
      "grad_norm": 0.3515629768371582,
      "learning_rate": 0.00019052444444444446,
      "loss": 1.2555,
      "step": 1600
    },
    {
      "epoch": 0.1511111111111111,
      "grad_norm": 0.3480081856250763,
      "learning_rate": 0.00018993185185185187,
      "loss": 1.2575,
      "step": 1700
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.4034773111343384,
      "learning_rate": 0.00018933925925925925,
      "loss": 1.2374,
      "step": 1800
    },
    {
      "epoch": 0.1688888888888889,
      "grad_norm": 0.3238525986671448,
      "learning_rate": 0.00018874666666666667,
      "loss": 1.2344,
      "step": 1900
    },
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 0.30510735511779785,
      "learning_rate": 0.00018815407407407408,
      "loss": 1.222,
      "step": 2000
    },
    {
      "epoch": 0.17777777777777778,
      "eval_loss": 1.1996197700500488,
      "eval_runtime": 204.412,
      "eval_samples_per_second": 195.683,
      "eval_steps_per_second": 12.23,
      "step": 2000
    },
    {
      "epoch": 0.18666666666666668,
      "grad_norm": 0.36437100172042847,
      "learning_rate": 0.0001875614814814815,
      "loss": 1.2625,
      "step": 2100
    },
    {
      "epoch": 0.19555555555555557,
      "grad_norm": 0.32218077778816223,
      "learning_rate": 0.0001869688888888889,
      "loss": 1.2647,
      "step": 2200
    },
    {
      "epoch": 0.20444444444444446,
      "grad_norm": 0.32352951169013977,
      "learning_rate": 0.00018637629629629631,
      "loss": 1.2343,
      "step": 2300
    },
    {
      "epoch": 0.21333333333333335,
      "grad_norm": 0.3589770197868347,
      "learning_rate": 0.0001857837037037037,
      "loss": 1.2209,
      "step": 2400
    },
    {
      "epoch": 0.2222222222222222,
      "grad_norm": 0.35791322588920593,
      "learning_rate": 0.0001851911111111111,
      "loss": 1.2143,
      "step": 2500
    },
    {
      "epoch": 0.2222222222222222,
      "eval_loss": 1.1991710662841797,
      "eval_runtime": 204.2506,
      "eval_samples_per_second": 195.838,
      "eval_steps_per_second": 12.24,
      "step": 2500
    },
    {
      "epoch": 0.2311111111111111,
      "grad_norm": 0.38693681359291077,
      "learning_rate": 0.00018459851851851852,
      "loss": 1.2268,
      "step": 2600
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.3360954225063324,
      "learning_rate": 0.00018400592592592594,
      "loss": 1.2243,
      "step": 2700
    },
    {
      "epoch": 0.24888888888888888,
      "grad_norm": 0.330667108297348,
      "learning_rate": 0.00018341333333333335,
      "loss": 1.2298,
      "step": 2800
    },
    {
      "epoch": 0.2577777777777778,
      "grad_norm": 0.3916926085948944,
      "learning_rate": 0.00018282074074074076,
      "loss": 1.1927,
      "step": 2900
    },
    {
      "epoch": 0.26666666666666666,
      "grad_norm": 0.31752219796180725,
      "learning_rate": 0.00018222814814814815,
      "loss": 1.2025,
      "step": 3000
    },
    {
      "epoch": 0.26666666666666666,
      "eval_loss": 1.1952130794525146,
      "eval_runtime": 204.2386,
      "eval_samples_per_second": 195.849,
      "eval_steps_per_second": 12.241,
      "step": 3000
    },
    {
      "epoch": 0.27555555555555555,
      "grad_norm": 0.3268093466758728,
      "learning_rate": 0.00018163555555555556,
      "loss": 1.2184,
      "step": 3100
    },
    {
      "epoch": 0.28444444444444444,
      "grad_norm": 0.3254320025444031,
      "learning_rate": 0.00018104296296296297,
      "loss": 1.2285,
      "step": 3200
    },
    {
      "epoch": 0.29333333333333333,
      "grad_norm": 0.31552207469940186,
      "learning_rate": 0.00018045037037037038,
      "loss": 1.2246,
      "step": 3300
    },
    {
      "epoch": 0.3022222222222222,
      "grad_norm": 0.31334951519966125,
      "learning_rate": 0.0001798577777777778,
      "loss": 1.2447,
      "step": 3400
    },
    {
      "epoch": 0.3111111111111111,
      "grad_norm": 0.36276116967201233,
      "learning_rate": 0.0001792651851851852,
      "loss": 1.2296,
      "step": 3500
    },
    {
      "epoch": 0.3111111111111111,
      "eval_loss": 1.1960554122924805,
      "eval_runtime": 204.1417,
      "eval_samples_per_second": 195.942,
      "eval_steps_per_second": 12.246,
      "step": 3500
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.36101552844047546,
      "learning_rate": 0.0001786725925925926,
      "loss": 1.2322,
      "step": 3600
    },
    {
      "epoch": 0.3288888888888889,
      "grad_norm": 0.3368752598762512,
      "learning_rate": 0.00017808,
      "loss": 1.2347,
      "step": 3700
    },
    {
      "epoch": 0.3377777777777778,
      "grad_norm": 0.3806149661540985,
      "learning_rate": 0.00017748740740740741,
      "loss": 1.2558,
      "step": 3800
    },
    {
      "epoch": 0.3466666666666667,
      "grad_norm": 0.3623046576976776,
      "learning_rate": 0.00017689481481481483,
      "loss": 1.2235,
      "step": 3900
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.3409222960472107,
      "learning_rate": 0.00017630222222222224,
      "loss": 1.2355,
      "step": 4000
    },
    {
      "epoch": 0.35555555555555557,
      "eval_loss": 1.1940457820892334,
      "eval_runtime": 204.2028,
      "eval_samples_per_second": 195.884,
      "eval_steps_per_second": 12.243,
      "step": 4000
    },
    {
      "epoch": 0.36444444444444446,
      "grad_norm": 0.3154677152633667,
      "learning_rate": 0.00017570962962962965,
      "loss": 1.2162,
      "step": 4100
    },
    {
      "epoch": 0.37333333333333335,
      "grad_norm": 0.3608536422252655,
      "learning_rate": 0.00017511703703703704,
      "loss": 1.2025,
      "step": 4200
    },
    {
      "epoch": 0.38222222222222224,
      "grad_norm": 0.3371579051017761,
      "learning_rate": 0.00017452444444444445,
      "loss": 1.2016,
      "step": 4300
    },
    {
      "epoch": 0.39111111111111113,
      "grad_norm": 0.3429274559020996,
      "learning_rate": 0.00017393185185185186,
      "loss": 1.2412,
      "step": 4400
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.36775708198547363,
      "learning_rate": 0.00017333925925925927,
      "loss": 1.2026,
      "step": 4500
    },
    {
      "epoch": 0.4,
      "eval_loss": 1.192813515663147,
      "eval_runtime": 204.5296,
      "eval_samples_per_second": 195.571,
      "eval_steps_per_second": 12.223,
      "step": 4500
    },
    {
      "epoch": 0.4088888888888889,
      "grad_norm": 0.3683474361896515,
      "learning_rate": 0.00017274666666666668,
      "loss": 1.2041,
      "step": 4600
    },
    {
      "epoch": 0.4177777777777778,
      "grad_norm": 0.30779749155044556,
      "learning_rate": 0.0001721540740740741,
      "loss": 1.2506,
      "step": 4700
    },
    {
      "epoch": 0.4266666666666667,
      "grad_norm": 0.4153028428554535,
      "learning_rate": 0.0001715614814814815,
      "loss": 1.2106,
      "step": 4800
    },
    {
      "epoch": 0.43555555555555553,
      "grad_norm": 0.41161754727363586,
      "learning_rate": 0.0001709688888888889,
      "loss": 1.2313,
      "step": 4900
    },
    {
      "epoch": 0.4444444444444444,
      "grad_norm": 0.4216914176940918,
      "learning_rate": 0.0001703762962962963,
      "loss": 1.1871,
      "step": 5000
    },
    {
      "epoch": 0.4444444444444444,
      "eval_loss": 1.1908516883850098,
      "eval_runtime": 204.2348,
      "eval_samples_per_second": 195.853,
      "eval_steps_per_second": 12.241,
      "step": 5000
    },
    {
      "epoch": 0.4533333333333333,
      "grad_norm": 0.39438360929489136,
      "learning_rate": 0.00016978370370370372,
      "loss": 1.2316,
      "step": 5100
    },
    {
      "epoch": 0.4622222222222222,
      "grad_norm": 0.36317166686058044,
      "learning_rate": 0.00016919111111111113,
      "loss": 1.2307,
      "step": 5200
    },
    {
      "epoch": 0.4711111111111111,
      "grad_norm": 0.3489602208137512,
      "learning_rate": 0.00016859851851851854,
      "loss": 1.1947,
      "step": 5300
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.33313706517219543,
      "learning_rate": 0.00016800592592592595,
      "loss": 1.2324,
      "step": 5400
    },
    {
      "epoch": 0.4888888888888889,
      "grad_norm": 0.3756319582462311,
      "learning_rate": 0.00016741333333333334,
      "loss": 1.1958,
      "step": 5500
    },
    {
      "epoch": 0.4888888888888889,
      "eval_loss": 1.1897600889205933,
      "eval_runtime": 204.2815,
      "eval_samples_per_second": 195.808,
      "eval_steps_per_second": 12.238,
      "step": 5500
    },
    {
      "epoch": 0.49777777777777776,
      "grad_norm": 0.34297963976860046,
      "learning_rate": 0.00016682074074074075,
      "loss": 1.2179,
      "step": 5600
    },
    {
      "epoch": 0.5066666666666667,
      "grad_norm": 0.37442517280578613,
      "learning_rate": 0.00016622814814814816,
      "loss": 1.235,
      "step": 5700
    },
    {
      "epoch": 0.5155555555555555,
      "grad_norm": 0.41133537888526917,
      "learning_rate": 0.00016563555555555557,
      "loss": 1.2173,
      "step": 5800
    },
    {
      "epoch": 0.5244444444444445,
      "grad_norm": 0.41351357102394104,
      "learning_rate": 0.000165042962962963,
      "loss": 1.2011,
      "step": 5900
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.38734593987464905,
      "learning_rate": 0.0001644503703703704,
      "loss": 1.1992,
      "step": 6000
    },
    {
      "epoch": 0.5333333333333333,
      "eval_loss": 1.189962387084961,
      "eval_runtime": 204.7902,
      "eval_samples_per_second": 195.322,
      "eval_steps_per_second": 12.208,
      "step": 6000
    },
    {
      "epoch": 0.5422222222222223,
      "grad_norm": 0.3852715790271759,
      "learning_rate": 0.00016385777777777778,
      "loss": 1.2012,
      "step": 6100
    },
    {
      "epoch": 0.5511111111111111,
      "grad_norm": 0.3757760524749756,
      "learning_rate": 0.0001632651851851852,
      "loss": 1.1887,
      "step": 6200
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.40164265036582947,
      "learning_rate": 0.0001626725925925926,
      "loss": 1.2133,
      "step": 6300
    },
    {
      "epoch": 0.5688888888888889,
      "grad_norm": 0.39218705892562866,
      "learning_rate": 0.00016208000000000002,
      "loss": 1.251,
      "step": 6400
    },
    {
      "epoch": 0.5777777777777777,
      "grad_norm": 0.38367515802383423,
      "learning_rate": 0.00016148740740740743,
      "loss": 1.2355,
      "step": 6500
    },
    {
      "epoch": 0.5777777777777777,
      "eval_loss": 1.1895966529846191,
      "eval_runtime": 204.8128,
      "eval_samples_per_second": 195.3,
      "eval_steps_per_second": 12.206,
      "step": 6500
    },
    {
      "epoch": 0.5866666666666667,
      "grad_norm": 0.39719507098197937,
      "learning_rate": 0.00016089481481481484,
      "loss": 1.2401,
      "step": 6600
    },
    {
      "epoch": 0.5955555555555555,
      "grad_norm": 0.40377381443977356,
      "learning_rate": 0.00016030222222222223,
      "loss": 1.235,
      "step": 6700
    },
    {
      "epoch": 0.6044444444444445,
      "grad_norm": 0.3593224585056305,
      "learning_rate": 0.00015970962962962964,
      "loss": 1.2257,
      "step": 6800
    },
    {
      "epoch": 0.6133333333333333,
      "grad_norm": 0.3818854093551636,
      "learning_rate": 0.00015911703703703705,
      "loss": 1.2339,
      "step": 6900
    },
    {
      "epoch": 0.6222222222222222,
      "grad_norm": 0.39401283860206604,
      "learning_rate": 0.00015852444444444447,
      "loss": 1.2015,
      "step": 7000
    },
    {
      "epoch": 0.6222222222222222,
      "eval_loss": 1.1889052391052246,
      "eval_runtime": 204.7982,
      "eval_samples_per_second": 195.314,
      "eval_steps_per_second": 12.207,
      "step": 7000
    },
    {
      "epoch": 0.6311111111111111,
      "grad_norm": 0.38625115156173706,
      "learning_rate": 0.00015793185185185188,
      "loss": 1.1959,
      "step": 7100
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.4324615001678467,
      "learning_rate": 0.00015733925925925926,
      "loss": 1.1824,
      "step": 7200
    },
    {
      "epoch": 0.6488888888888888,
      "grad_norm": 0.3776014745235443,
      "learning_rate": 0.00015674666666666667,
      "loss": 1.2006,
      "step": 7300
    },
    {
      "epoch": 0.6577777777777778,
      "grad_norm": 0.38054487109184265,
      "learning_rate": 0.0001561540740740741,
      "loss": 1.1837,
      "step": 7400
    },
    {
      "epoch": 0.6666666666666666,
      "grad_norm": 0.4486677050590515,
      "learning_rate": 0.0001555614814814815,
      "loss": 1.241,
      "step": 7500
    },
    {
      "epoch": 0.6666666666666666,
      "eval_loss": 1.1882579326629639,
      "eval_runtime": 204.7928,
      "eval_samples_per_second": 195.319,
      "eval_steps_per_second": 12.207,
      "step": 7500
    },
    {
      "epoch": 0.6755555555555556,
      "grad_norm": 0.37536635994911194,
      "learning_rate": 0.00015496888888888888,
      "loss": 1.2134,
      "step": 7600
    },
    {
      "epoch": 0.6844444444444444,
      "grad_norm": 0.4016282260417938,
      "learning_rate": 0.0001543762962962963,
      "loss": 1.1923,
      "step": 7700
    },
    {
      "epoch": 0.6933333333333334,
      "grad_norm": 0.5707520842552185,
      "learning_rate": 0.0001537837037037037,
      "loss": 1.2268,
      "step": 7800
    },
    {
      "epoch": 0.7022222222222222,
      "grad_norm": 0.43527641892433167,
      "learning_rate": 0.00015319111111111112,
      "loss": 1.1767,
      "step": 7900
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.43521636724472046,
      "learning_rate": 0.0001525985185185185,
      "loss": 1.2088,
      "step": 8000
    },
    {
      "epoch": 0.7111111111111111,
      "eval_loss": 1.1867698431015015,
      "eval_runtime": 204.6219,
      "eval_samples_per_second": 195.482,
      "eval_steps_per_second": 12.218,
      "step": 8000
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.3577304184436798,
      "learning_rate": 0.00015200592592592592,
      "loss": 1.2089,
      "step": 8100
    },
    {
      "epoch": 0.7288888888888889,
      "grad_norm": 0.40156790614128113,
      "learning_rate": 0.00015141333333333333,
      "loss": 1.2261,
      "step": 8200
    },
    {
      "epoch": 0.7377777777777778,
      "grad_norm": 0.38975411653518677,
      "learning_rate": 0.00015082074074074074,
      "loss": 1.1941,
      "step": 8300
    },
    {
      "epoch": 0.7466666666666667,
      "grad_norm": 0.35627415776252747,
      "learning_rate": 0.00015022814814814815,
      "loss": 1.2256,
      "step": 8400
    },
    {
      "epoch": 0.7555555555555555,
      "grad_norm": 0.4286730885505676,
      "learning_rate": 0.00014963555555555557,
      "loss": 1.2062,
      "step": 8500
    },
    {
      "epoch": 0.7555555555555555,
      "eval_loss": 1.1860591173171997,
      "eval_runtime": 204.4757,
      "eval_samples_per_second": 195.622,
      "eval_steps_per_second": 12.226,
      "step": 8500
    },
    {
      "epoch": 0.7644444444444445,
      "grad_norm": 0.37779825925827026,
      "learning_rate": 0.00014904296296296295,
      "loss": 1.2168,
      "step": 8600
    },
    {
      "epoch": 0.7733333333333333,
      "grad_norm": 0.40533626079559326,
      "learning_rate": 0.00014845037037037036,
      "loss": 1.2146,
      "step": 8700
    },
    {
      "epoch": 0.7822222222222223,
      "grad_norm": 0.514379620552063,
      "learning_rate": 0.00014785777777777777,
      "loss": 1.1984,
      "step": 8800
    },
    {
      "epoch": 0.7911111111111111,
      "grad_norm": 0.41781890392303467,
      "learning_rate": 0.0001472651851851852,
      "loss": 1.2079,
      "step": 8900
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.3977486491203308,
      "learning_rate": 0.0001466725925925926,
      "loss": 1.2223,
      "step": 9000
    },
    {
      "epoch": 0.8,
      "eval_loss": 1.186311960220337,
      "eval_runtime": 204.4778,
      "eval_samples_per_second": 195.62,
      "eval_steps_per_second": 12.226,
      "step": 9000
    },
    {
      "epoch": 0.8088888888888889,
      "grad_norm": 0.38979414105415344,
      "learning_rate": 0.00014608,
      "loss": 1.2243,
      "step": 9100
    },
    {
      "epoch": 0.8177777777777778,
      "grad_norm": 0.4448181092739105,
      "learning_rate": 0.0001454874074074074,
      "loss": 1.1935,
      "step": 9200
    },
    {
      "epoch": 0.8266666666666667,
      "grad_norm": 0.4354219138622284,
      "learning_rate": 0.0001448948148148148,
      "loss": 1.2004,
      "step": 9300
    },
    {
      "epoch": 0.8355555555555556,
      "grad_norm": 0.3944609463214874,
      "learning_rate": 0.00014430222222222222,
      "loss": 1.2107,
      "step": 9400
    },
    {
      "epoch": 0.8444444444444444,
      "grad_norm": 0.3725568652153015,
      "learning_rate": 0.00014370962962962963,
      "loss": 1.2263,
      "step": 9500
    },
    {
      "epoch": 0.8444444444444444,
      "eval_loss": 1.18534517288208,
      "eval_runtime": 204.3876,
      "eval_samples_per_second": 195.707,
      "eval_steps_per_second": 12.232,
      "step": 9500
    },
    {
      "epoch": 0.8533333333333334,
      "grad_norm": 0.39738935232162476,
      "learning_rate": 0.00014311703703703704,
      "loss": 1.2051,
      "step": 9600
    },
    {
      "epoch": 0.8622222222222222,
      "grad_norm": 0.45126625895500183,
      "learning_rate": 0.00014252444444444446,
      "loss": 1.2008,
      "step": 9700
    },
    {
      "epoch": 0.8711111111111111,
      "grad_norm": 0.39047950506210327,
      "learning_rate": 0.00014193185185185184,
      "loss": 1.2156,
      "step": 9800
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.4118663966655731,
      "learning_rate": 0.00014133925925925925,
      "loss": 1.2306,
      "step": 9900
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 0.48785191774368286,
      "learning_rate": 0.00014074666666666667,
      "loss": 1.2127,
      "step": 10000
    },
    {
      "epoch": 0.8888888888888888,
      "eval_loss": 1.1853110790252686,
      "eval_runtime": 204.3132,
      "eval_samples_per_second": 195.778,
      "eval_steps_per_second": 12.236,
      "step": 10000
    },
    {
      "epoch": 0.8977777777777778,
      "grad_norm": 0.5041443109512329,
      "learning_rate": 0.00014015407407407408,
      "loss": 1.1964,
      "step": 10100
    },
    {
      "epoch": 0.9066666666666666,
      "grad_norm": 0.39890778064727783,
      "learning_rate": 0.0001395614814814815,
      "loss": 1.2056,
      "step": 10200
    },
    {
      "epoch": 0.9155555555555556,
      "grad_norm": 0.381163090467453,
      "learning_rate": 0.0001389688888888889,
      "loss": 1.1964,
      "step": 10300
    },
    {
      "epoch": 0.9244444444444444,
      "grad_norm": 0.4043337106704712,
      "learning_rate": 0.0001383762962962963,
      "loss": 1.2411,
      "step": 10400
    },
    {
      "epoch": 0.9333333333333333,
      "grad_norm": 0.4091155529022217,
      "learning_rate": 0.0001377837037037037,
      "loss": 1.1998,
      "step": 10500
    },
    {
      "epoch": 0.9333333333333333,
      "eval_loss": 1.1839942932128906,
      "eval_runtime": 204.3622,
      "eval_samples_per_second": 195.731,
      "eval_steps_per_second": 12.233,
      "step": 10500
    },
    {
      "epoch": 0.9422222222222222,
      "grad_norm": 0.3940422236919403,
      "learning_rate": 0.0001371911111111111,
      "loss": 1.2085,
      "step": 10600
    },
    {
      "epoch": 0.9511111111111111,
      "grad_norm": 0.4147692024707794,
      "learning_rate": 0.00013659851851851852,
      "loss": 1.2203,
      "step": 10700
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.4000944495201111,
      "learning_rate": 0.00013600592592592593,
      "loss": 1.1957,
      "step": 10800
    },
    {
      "epoch": 0.9688888888888889,
      "grad_norm": 0.4547572731971741,
      "learning_rate": 0.00013541333333333335,
      "loss": 1.1921,
      "step": 10900
    },
    {
      "epoch": 0.9777777777777777,
      "grad_norm": 0.40201687812805176,
      "learning_rate": 0.00013482074074074073,
      "loss": 1.202,
      "step": 11000
    },
    {
      "epoch": 0.9777777777777777,
      "eval_loss": 1.1831597089767456,
      "eval_runtime": 204.6849,
      "eval_samples_per_second": 195.422,
      "eval_steps_per_second": 12.214,
      "step": 11000
    },
    {
      "epoch": 0.9866666666666667,
      "grad_norm": 0.45919445157051086,
      "learning_rate": 0.00013422814814814814,
      "loss": 1.2391,
      "step": 11100
    },
    {
      "epoch": 0.9955555555555555,
      "grad_norm": 0.40434685349464417,
      "learning_rate": 0.00013363555555555556,
      "loss": 1.2094,
      "step": 11200
    },
    {
      "epoch": 1.0044444444444445,
      "grad_norm": 0.5497487187385559,
      "learning_rate": 0.00013304296296296297,
      "loss": 1.2,
      "step": 11300
    },
    {
      "epoch": 1.0133333333333334,
      "grad_norm": 0.5189844369888306,
      "learning_rate": 0.00013245037037037038,
      "loss": 1.2169,
      "step": 11400
    },
    {
      "epoch": 1.0222222222222221,
      "grad_norm": 0.46806299686431885,
      "learning_rate": 0.0001318577777777778,
      "loss": 1.1592,
      "step": 11500
    },
    {
      "epoch": 1.0222222222222221,
      "eval_loss": 1.184322476387024,
      "eval_runtime": 204.3292,
      "eval_samples_per_second": 195.762,
      "eval_steps_per_second": 12.235,
      "step": 11500
    },
    {
      "epoch": 1.031111111111111,
      "grad_norm": 0.40871989727020264,
      "learning_rate": 0.0001312651851851852,
      "loss": 1.1925,
      "step": 11600
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.4153275191783905,
      "learning_rate": 0.0001306725925925926,
      "loss": 1.1714,
      "step": 11700
    },
    {
      "epoch": 1.048888888888889,
      "grad_norm": 0.4493893086910248,
      "learning_rate": 0.00013008,
      "loss": 1.1899,
      "step": 11800
    },
    {
      "epoch": 1.0577777777777777,
      "grad_norm": 0.3841085135936737,
      "learning_rate": 0.0001294874074074074,
      "loss": 1.1589,
      "step": 11900
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.4117085337638855,
      "learning_rate": 0.00012889481481481483,
      "loss": 1.1665,
      "step": 12000
    },
    {
      "epoch": 1.0666666666666667,
      "eval_loss": 1.185520887374878,
      "eval_runtime": 204.3529,
      "eval_samples_per_second": 195.74,
      "eval_steps_per_second": 12.234,
      "step": 12000
    },
    {
      "epoch": 1.0755555555555556,
      "grad_norm": 0.38866761326789856,
      "learning_rate": 0.00012830222222222224,
      "loss": 1.1794,
      "step": 12100
    },
    {
      "epoch": 1.0844444444444445,
      "grad_norm": 0.4183608591556549,
      "learning_rate": 0.00012770962962962965,
      "loss": 1.1982,
      "step": 12200
    },
    {
      "epoch": 1.0933333333333333,
      "grad_norm": 0.3993000090122223,
      "learning_rate": 0.00012711703703703703,
      "loss": 1.1834,
      "step": 12300
    },
    {
      "epoch": 1.1022222222222222,
      "grad_norm": 0.3980107009410858,
      "learning_rate": 0.00012652444444444445,
      "loss": 1.1762,
      "step": 12400
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 0.4778849482536316,
      "learning_rate": 0.00012593185185185186,
      "loss": 1.1685,
      "step": 12500
    },
    {
      "epoch": 1.1111111111111112,
      "eval_loss": 1.1846520900726318,
      "eval_runtime": 204.5959,
      "eval_samples_per_second": 195.507,
      "eval_steps_per_second": 12.219,
      "step": 12500
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.47671806812286377,
      "learning_rate": 0.00012533925925925927,
      "loss": 1.1689,
      "step": 12600
    },
    {
      "epoch": 1.1288888888888888,
      "grad_norm": 0.5371220111846924,
      "learning_rate": 0.00012474666666666668,
      "loss": 1.1755,
      "step": 12700
    },
    {
      "epoch": 1.1377777777777778,
      "grad_norm": 0.40747490525245667,
      "learning_rate": 0.0001241540740740741,
      "loss": 1.193,
      "step": 12800
    },
    {
      "epoch": 1.1466666666666667,
      "grad_norm": 0.42189064621925354,
      "learning_rate": 0.00012356148148148148,
      "loss": 1.1999,
      "step": 12900
    },
    {
      "epoch": 1.1555555555555554,
      "grad_norm": 0.47287604212760925,
      "learning_rate": 0.0001229688888888889,
      "loss": 1.1508,
      "step": 13000
    },
    {
      "epoch": 1.1555555555555554,
      "eval_loss": 1.1854643821716309,
      "eval_runtime": 204.6554,
      "eval_samples_per_second": 195.45,
      "eval_steps_per_second": 12.216,
      "step": 13000
    },
    {
      "epoch": 1.1644444444444444,
      "grad_norm": 0.38814494013786316,
      "learning_rate": 0.0001223762962962963,
      "loss": 1.228,
      "step": 13100
    },
    {
      "epoch": 1.1733333333333333,
      "grad_norm": 0.5738393664360046,
      "learning_rate": 0.00012178370370370372,
      "loss": 1.1804,
      "step": 13200
    },
    {
      "epoch": 1.1822222222222223,
      "grad_norm": 0.4598742127418518,
      "learning_rate": 0.00012119111111111113,
      "loss": 1.1834,
      "step": 13300
    },
    {
      "epoch": 1.1911111111111112,
      "grad_norm": 0.47072774171829224,
      "learning_rate": 0.00012059851851851853,
      "loss": 1.1617,
      "step": 13400
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.4023643732070923,
      "learning_rate": 0.00012000592592592593,
      "loss": 1.187,
      "step": 13500
    },
    {
      "epoch": 1.2,
      "eval_loss": 1.1844531297683716,
      "eval_runtime": 205.5571,
      "eval_samples_per_second": 194.593,
      "eval_steps_per_second": 12.162,
      "step": 13500
    },
    {
      "epoch": 1.208888888888889,
      "grad_norm": 0.5081279277801514,
      "learning_rate": 0.00011941333333333334,
      "loss": 1.1671,
      "step": 13600
    },
    {
      "epoch": 1.2177777777777778,
      "grad_norm": 0.42195937037467957,
      "learning_rate": 0.00011882074074074075,
      "loss": 1.1928,
      "step": 13700
    },
    {
      "epoch": 1.2266666666666666,
      "grad_norm": 0.4060611128807068,
      "learning_rate": 0.00011822814814814815,
      "loss": 1.174,
      "step": 13800
    },
    {
      "epoch": 1.2355555555555555,
      "grad_norm": 0.4669930040836334,
      "learning_rate": 0.00011763555555555556,
      "loss": 1.1876,
      "step": 13900
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 0.46947699785232544,
      "learning_rate": 0.00011704296296296297,
      "loss": 1.1612,
      "step": 14000
    },
    {
      "epoch": 1.2444444444444445,
      "eval_loss": 1.1851751804351807,
      "eval_runtime": 205.4094,
      "eval_samples_per_second": 194.733,
      "eval_steps_per_second": 12.171,
      "step": 14000
    },
    {
      "epoch": 1.2533333333333334,
      "grad_norm": 0.5027799010276794,
      "learning_rate": 0.00011645037037037037,
      "loss": 1.1794,
      "step": 14100
    },
    {
      "epoch": 1.2622222222222224,
      "grad_norm": 0.5200689435005188,
      "learning_rate": 0.00011585777777777778,
      "loss": 1.1724,
      "step": 14200
    },
    {
      "epoch": 1.271111111111111,
      "grad_norm": 0.4792328178882599,
      "learning_rate": 0.00011526518518518518,
      "loss": 1.1848,
      "step": 14300
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.35782909393310547,
      "learning_rate": 0.0001146725925925926,
      "loss": 1.1363,
      "step": 14400
    },
    {
      "epoch": 1.2888888888888888,
      "grad_norm": 0.4071650207042694,
      "learning_rate": 0.00011408,
      "loss": 1.1694,
      "step": 14500
    },
    {
      "epoch": 1.2888888888888888,
      "eval_loss": 1.1841505765914917,
      "eval_runtime": 204.7156,
      "eval_samples_per_second": 195.393,
      "eval_steps_per_second": 12.212,
      "step": 14500
    },
    {
      "epoch": 1.2977777777777777,
      "grad_norm": 0.43776336312294006,
      "learning_rate": 0.00011348740740740742,
      "loss": 1.1796,
      "step": 14600
    },
    {
      "epoch": 1.3066666666666666,
      "grad_norm": 0.48315006494522095,
      "learning_rate": 0.00011289481481481483,
      "loss": 1.211,
      "step": 14700
    },
    {
      "epoch": 1.3155555555555556,
      "grad_norm": 0.3498375713825226,
      "learning_rate": 0.00011230222222222221,
      "loss": 1.1705,
      "step": 14800
    },
    {
      "epoch": 1.3244444444444445,
      "grad_norm": 0.4883270263671875,
      "learning_rate": 0.00011170962962962963,
      "loss": 1.1761,
      "step": 14900
    },
    {
      "epoch": 1.3333333333333333,
      "grad_norm": 0.4965587854385376,
      "learning_rate": 0.00011111703703703704,
      "loss": 1.1664,
      "step": 15000
    },
    {
      "epoch": 1.3333333333333333,
      "eval_loss": 1.1847127676010132,
      "eval_runtime": 204.3908,
      "eval_samples_per_second": 195.703,
      "eval_steps_per_second": 12.231,
      "step": 15000
    },
    {
      "epoch": 1.3422222222222222,
      "grad_norm": 0.43700477480888367,
      "learning_rate": 0.00011052444444444445,
      "loss": 1.173,
      "step": 15100
    },
    {
      "epoch": 1.3511111111111112,
      "grad_norm": 0.4545901119709015,
      "learning_rate": 0.00010993185185185186,
      "loss": 1.1756,
      "step": 15200
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.4493149220943451,
      "learning_rate": 0.00010933925925925928,
      "loss": 1.1497,
      "step": 15300
    },
    {
      "epoch": 1.3688888888888888,
      "grad_norm": 0.4531407654285431,
      "learning_rate": 0.00010874666666666666,
      "loss": 1.1851,
      "step": 15400
    },
    {
      "epoch": 1.3777777777777778,
      "grad_norm": 0.4433598816394806,
      "learning_rate": 0.00010815407407407407,
      "loss": 1.1958,
      "step": 15500
    },
    {
      "epoch": 1.3777777777777778,
      "eval_loss": 1.1839815378189087,
      "eval_runtime": 204.4133,
      "eval_samples_per_second": 195.682,
      "eval_steps_per_second": 12.23,
      "step": 15500
    },
    {
      "epoch": 1.3866666666666667,
      "grad_norm": 0.5378087759017944,
      "learning_rate": 0.00010756148148148148,
      "loss": 1.1786,
      "step": 15600
    },
    {
      "epoch": 1.3955555555555557,
      "grad_norm": 0.45634570717811584,
      "learning_rate": 0.0001069688888888889,
      "loss": 1.1488,
      "step": 15700
    },
    {
      "epoch": 1.4044444444444444,
      "grad_norm": 0.5718585848808289,
      "learning_rate": 0.00010637629629629631,
      "loss": 1.1621,
      "step": 15800
    },
    {
      "epoch": 1.4133333333333333,
      "grad_norm": 0.4868312478065491,
      "learning_rate": 0.00010578370370370372,
      "loss": 1.1779,
      "step": 15900
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.47228750586509705,
      "learning_rate": 0.0001051911111111111,
      "loss": 1.1427,
      "step": 16000
    },
    {
      "epoch": 1.4222222222222223,
      "eval_loss": 1.1838065385818481,
      "eval_runtime": 204.3149,
      "eval_samples_per_second": 195.776,
      "eval_steps_per_second": 12.236,
      "step": 16000
    },
    {
      "epoch": 1.431111111111111,
      "grad_norm": 0.46839532256126404,
      "learning_rate": 0.00010459851851851852,
      "loss": 1.174,
      "step": 16100
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.5229770541191101,
      "learning_rate": 0.00010400592592592593,
      "loss": 1.1935,
      "step": 16200
    },
    {
      "epoch": 1.448888888888889,
      "grad_norm": 0.41666802763938904,
      "learning_rate": 0.00010341333333333334,
      "loss": 1.1764,
      "step": 16300
    },
    {
      "epoch": 1.4577777777777778,
      "grad_norm": 0.4803791046142578,
      "learning_rate": 0.00010282074074074075,
      "loss": 1.1809,
      "step": 16400
    },
    {
      "epoch": 1.4666666666666668,
      "grad_norm": 0.5631839632987976,
      "learning_rate": 0.00010222814814814817,
      "loss": 1.1681,
      "step": 16500
    },
    {
      "epoch": 1.4666666666666668,
      "eval_loss": 1.1829500198364258,
      "eval_runtime": 204.578,
      "eval_samples_per_second": 195.524,
      "eval_steps_per_second": 12.22,
      "step": 16500
    },
    {
      "epoch": 1.4755555555555555,
      "grad_norm": 0.4188983738422394,
      "learning_rate": 0.00010163555555555555,
      "loss": 1.1374,
      "step": 16600
    },
    {
      "epoch": 1.4844444444444445,
      "grad_norm": 0.45306655764579773,
      "learning_rate": 0.00010104296296296296,
      "loss": 1.1917,
      "step": 16700
    },
    {
      "epoch": 1.4933333333333334,
      "grad_norm": 0.45824024081230164,
      "learning_rate": 0.00010045037037037037,
      "loss": 1.1511,
      "step": 16800
    },
    {
      "epoch": 1.5022222222222221,
      "grad_norm": 0.4658835232257843,
      "learning_rate": 9.985777777777779e-05,
      "loss": 1.1676,
      "step": 16900
    },
    {
      "epoch": 1.511111111111111,
      "grad_norm": 0.48346146941185,
      "learning_rate": 9.92651851851852e-05,
      "loss": 1.1681,
      "step": 17000
    },
    {
      "epoch": 1.511111111111111,
      "eval_loss": 1.1832078695297241,
      "eval_runtime": 204.4756,
      "eval_samples_per_second": 195.622,
      "eval_steps_per_second": 12.226,
      "step": 17000
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.4919096827507019,
      "learning_rate": 9.86725925925926e-05,
      "loss": 1.1458,
      "step": 17100
    },
    {
      "epoch": 1.528888888888889,
      "grad_norm": 0.4517675042152405,
      "learning_rate": 9.808000000000001e-05,
      "loss": 1.1718,
      "step": 17200
    },
    {
      "epoch": 1.537777777777778,
      "grad_norm": 0.43681642413139343,
      "learning_rate": 9.748740740740742e-05,
      "loss": 1.1529,
      "step": 17300
    },
    {
      "epoch": 1.5466666666666666,
      "grad_norm": 0.5482986569404602,
      "learning_rate": 9.689481481481482e-05,
      "loss": 1.1423,
      "step": 17400
    },
    {
      "epoch": 1.5555555555555556,
      "grad_norm": 0.49099498987197876,
      "learning_rate": 9.630222222222223e-05,
      "loss": 1.177,
      "step": 17500
    },
    {
      "epoch": 1.5555555555555556,
      "eval_loss": 1.1846755743026733,
      "eval_runtime": 204.3757,
      "eval_samples_per_second": 195.718,
      "eval_steps_per_second": 12.232,
      "step": 17500
    },
    {
      "epoch": 1.5644444444444443,
      "grad_norm": 0.4521946609020233,
      "learning_rate": 9.570962962962964e-05,
      "loss": 1.1418,
      "step": 17600
    },
    {
      "epoch": 1.5733333333333333,
      "grad_norm": 0.41962432861328125,
      "learning_rate": 9.511703703703704e-05,
      "loss": 1.1659,
      "step": 17700
    },
    {
      "epoch": 1.5822222222222222,
      "grad_norm": 0.46469953656196594,
      "learning_rate": 9.452444444444445e-05,
      "loss": 1.1735,
      "step": 17800
    },
    {
      "epoch": 1.5911111111111111,
      "grad_norm": 0.5239552855491638,
      "learning_rate": 9.393185185185185e-05,
      "loss": 1.1787,
      "step": 17900
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.49550166726112366,
      "learning_rate": 9.333925925925927e-05,
      "loss": 1.1744,
      "step": 18000
    },
    {
      "epoch": 1.6,
      "eval_loss": 1.18268883228302,
      "eval_runtime": 204.4439,
      "eval_samples_per_second": 195.653,
      "eval_steps_per_second": 12.228,
      "step": 18000
    },
    {
      "epoch": 1.608888888888889,
      "grad_norm": 0.4206889867782593,
      "learning_rate": 9.274666666666666e-05,
      "loss": 1.1941,
      "step": 18100
    },
    {
      "epoch": 1.6177777777777778,
      "grad_norm": 0.4595242738723755,
      "learning_rate": 9.215407407407408e-05,
      "loss": 1.1295,
      "step": 18200
    },
    {
      "epoch": 1.6266666666666667,
      "grad_norm": 0.5320048928260803,
      "learning_rate": 9.156148148148147e-05,
      "loss": 1.1633,
      "step": 18300
    },
    {
      "epoch": 1.6355555555555554,
      "grad_norm": 0.46050402522087097,
      "learning_rate": 9.096888888888889e-05,
      "loss": 1.1885,
      "step": 18400
    },
    {
      "epoch": 1.6444444444444444,
      "grad_norm": 0.529876708984375,
      "learning_rate": 9.03762962962963e-05,
      "loss": 1.1693,
      "step": 18500
    },
    {
      "epoch": 1.6444444444444444,
      "eval_loss": 1.1819586753845215,
      "eval_runtime": 204.3897,
      "eval_samples_per_second": 195.705,
      "eval_steps_per_second": 12.232,
      "step": 18500
    },
    {
      "epoch": 1.6533333333333333,
      "grad_norm": 0.6272718906402588,
      "learning_rate": 8.97837037037037e-05,
      "loss": 1.1886,
      "step": 18600
    },
    {
      "epoch": 1.6622222222222223,
      "grad_norm": 0.4523825943470001,
      "learning_rate": 8.919111111111111e-05,
      "loss": 1.1636,
      "step": 18700
    },
    {
      "epoch": 1.6711111111111112,
      "grad_norm": 0.5249812602996826,
      "learning_rate": 8.859851851851852e-05,
      "loss": 1.1855,
      "step": 18800
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.44722580909729004,
      "learning_rate": 8.800592592592592e-05,
      "loss": 1.1931,
      "step": 18900
    },
    {
      "epoch": 1.6888888888888889,
      "grad_norm": 0.4463529586791992,
      "learning_rate": 8.741333333333333e-05,
      "loss": 1.1908,
      "step": 19000
    },
    {
      "epoch": 1.6888888888888889,
      "eval_loss": 1.1817688941955566,
      "eval_runtime": 204.5079,
      "eval_samples_per_second": 195.591,
      "eval_steps_per_second": 12.224,
      "step": 19000
    },
    {
      "epoch": 1.6977777777777778,
      "grad_norm": 0.5087343454360962,
      "learning_rate": 8.682074074074074e-05,
      "loss": 1.1517,
      "step": 19100
    },
    {
      "epoch": 1.7066666666666666,
      "grad_norm": 0.5271133184432983,
      "learning_rate": 8.622814814814814e-05,
      "loss": 1.1573,
      "step": 19200
    },
    {
      "epoch": 1.7155555555555555,
      "grad_norm": 0.5016409158706665,
      "learning_rate": 8.563555555555555e-05,
      "loss": 1.1387,
      "step": 19300
    },
    {
      "epoch": 1.7244444444444444,
      "grad_norm": 0.45203065872192383,
      "learning_rate": 8.504296296296297e-05,
      "loss": 1.1677,
      "step": 19400
    },
    {
      "epoch": 1.7333333333333334,
      "grad_norm": 0.5481048226356506,
      "learning_rate": 8.445037037037038e-05,
      "loss": 1.1835,
      "step": 19500
    },
    {
      "epoch": 1.7333333333333334,
      "eval_loss": 1.1814079284667969,
      "eval_runtime": 204.4387,
      "eval_samples_per_second": 195.658,
      "eval_steps_per_second": 12.229,
      "step": 19500
    },
    {
      "epoch": 1.7422222222222223,
      "grad_norm": 0.4722009301185608,
      "learning_rate": 8.385777777777778e-05,
      "loss": 1.1851,
      "step": 19600
    },
    {
      "epoch": 1.751111111111111,
      "grad_norm": 0.5217303037643433,
      "learning_rate": 8.326518518518519e-05,
      "loss": 1.1762,
      "step": 19700
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.49125200510025024,
      "learning_rate": 8.26725925925926e-05,
      "loss": 1.2018,
      "step": 19800
    },
    {
      "epoch": 1.7688888888888887,
      "grad_norm": 0.5609396696090698,
      "learning_rate": 8.208e-05,
      "loss": 1.1635,
      "step": 19900
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 0.4343249499797821,
      "learning_rate": 8.148740740740741e-05,
      "loss": 1.144,
      "step": 20000
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 1.1819264888763428,
      "eval_runtime": 204.4558,
      "eval_samples_per_second": 195.641,
      "eval_steps_per_second": 12.228,
      "step": 20000
    },
    {
      "epoch": 1.7866666666666666,
      "grad_norm": 0.546994686126709,
      "learning_rate": 8.089481481481482e-05,
      "loss": 1.1711,
      "step": 20100
    },
    {
      "epoch": 1.7955555555555556,
      "grad_norm": 0.555572509765625,
      "learning_rate": 8.030222222222222e-05,
      "loss": 1.1572,
      "step": 20200
    },
    {
      "epoch": 1.8044444444444445,
      "grad_norm": 0.5267819166183472,
      "learning_rate": 7.970962962962963e-05,
      "loss": 1.1462,
      "step": 20300
    },
    {
      "epoch": 1.8133333333333335,
      "grad_norm": 0.5500595569610596,
      "learning_rate": 7.911703703703705e-05,
      "loss": 1.1792,
      "step": 20400
    },
    {
      "epoch": 1.8222222222222222,
      "grad_norm": 0.45024949312210083,
      "learning_rate": 7.852444444444445e-05,
      "loss": 1.1633,
      "step": 20500
    },
    {
      "epoch": 1.8222222222222222,
      "eval_loss": 1.1804603338241577,
      "eval_runtime": 204.4785,
      "eval_samples_per_second": 195.62,
      "eval_steps_per_second": 12.226,
      "step": 20500
    },
    {
      "epoch": 1.8311111111111111,
      "grad_norm": 0.6437369585037231,
      "learning_rate": 7.793185185185186e-05,
      "loss": 1.1424,
      "step": 20600
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.5164480209350586,
      "learning_rate": 7.733925925925927e-05,
      "loss": 1.1867,
      "step": 20700
    },
    {
      "epoch": 1.8488888888888888,
      "grad_norm": 0.5409186482429504,
      "learning_rate": 7.674666666666667e-05,
      "loss": 1.1707,
      "step": 20800
    },
    {
      "epoch": 1.8577777777777778,
      "grad_norm": 0.4753688871860504,
      "learning_rate": 7.615407407407408e-05,
      "loss": 1.1401,
      "step": 20900
    },
    {
      "epoch": 1.8666666666666667,
      "grad_norm": 0.47671037912368774,
      "learning_rate": 7.556148148148149e-05,
      "loss": 1.1617,
      "step": 21000
    },
    {
      "epoch": 1.8666666666666667,
      "eval_loss": 1.1805890798568726,
      "eval_runtime": 204.5425,
      "eval_samples_per_second": 195.558,
      "eval_steps_per_second": 12.222,
      "step": 21000
    },
    {
      "epoch": 1.8755555555555556,
      "grad_norm": 0.5457398295402527,
      "learning_rate": 7.496888888888889e-05,
      "loss": 1.1561,
      "step": 21100
    },
    {
      "epoch": 1.8844444444444446,
      "grad_norm": 0.507830023765564,
      "learning_rate": 7.43762962962963e-05,
      "loss": 1.1546,
      "step": 21200
    },
    {
      "epoch": 1.8933333333333333,
      "grad_norm": 0.3691580295562744,
      "learning_rate": 7.378370370370372e-05,
      "loss": 1.1544,
      "step": 21300
    },
    {
      "epoch": 1.9022222222222223,
      "grad_norm": 0.5022292733192444,
      "learning_rate": 7.319111111111111e-05,
      "loss": 1.2041,
      "step": 21400
    },
    {
      "epoch": 1.911111111111111,
      "grad_norm": 0.5080850124359131,
      "learning_rate": 7.259851851851853e-05,
      "loss": 1.1723,
      "step": 21500
    },
    {
      "epoch": 1.911111111111111,
      "eval_loss": 1.180245280265808,
      "eval_runtime": 203.9871,
      "eval_samples_per_second": 196.091,
      "eval_steps_per_second": 12.256,
      "step": 21500
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.4876927137374878,
      "learning_rate": 7.200592592592594e-05,
      "loss": 1.1727,
      "step": 21600
    },
    {
      "epoch": 1.9288888888888889,
      "grad_norm": 0.4625127613544464,
      "learning_rate": 7.141333333333334e-05,
      "loss": 1.1872,
      "step": 21700
    },
    {
      "epoch": 1.9377777777777778,
      "grad_norm": 0.43722209334373474,
      "learning_rate": 7.082074074074075e-05,
      "loss": 1.1955,
      "step": 21800
    },
    {
      "epoch": 1.9466666666666668,
      "grad_norm": 0.48595207929611206,
      "learning_rate": 7.022814814814816e-05,
      "loss": 1.1561,
      "step": 21900
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 0.567503035068512,
      "learning_rate": 6.963555555555556e-05,
      "loss": 1.1901,
      "step": 22000
    },
    {
      "epoch": 1.9555555555555557,
      "eval_loss": 1.180033802986145,
      "eval_runtime": 203.8729,
      "eval_samples_per_second": 196.201,
      "eval_steps_per_second": 12.263,
      "step": 22000
    },
    {
      "epoch": 1.9644444444444444,
      "grad_norm": 0.5612161159515381,
      "learning_rate": 6.904296296296297e-05,
      "loss": 1.1824,
      "step": 22100
    },
    {
      "epoch": 1.9733333333333334,
      "grad_norm": 0.5056868195533752,
      "learning_rate": 6.845037037037037e-05,
      "loss": 1.1716,
      "step": 22200
    },
    {
      "epoch": 1.982222222222222,
      "grad_norm": 0.4704643785953522,
      "learning_rate": 6.785777777777778e-05,
      "loss": 1.1476,
      "step": 22300
    },
    {
      "epoch": 1.991111111111111,
      "grad_norm": 0.4386395514011383,
      "learning_rate": 6.726518518518518e-05,
      "loss": 1.1943,
      "step": 22400
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.4669565260410309,
      "learning_rate": 6.667259259259259e-05,
      "loss": 1.1338,
      "step": 22500
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.1799790859222412,
      "eval_runtime": 203.98,
      "eval_samples_per_second": 196.098,
      "eval_steps_per_second": 12.256,
      "step": 22500
    }
  ],
  "logging_steps": 100,
  "max_steps": 33750,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.46123787068375e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
